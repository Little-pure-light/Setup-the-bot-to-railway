from dotenv import load_dotenv 
load_dotenv() 
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import asyncio
import os

# å¼•å…¥ backend è³‡æ–™å¤¾ä¸‹çš„å„å€‹ router
from backend.chat_router import router as chat_router
from backend.memory_router import router as memory_router
from backend.openai_handler import router as openai_router
from backend.file_upload import router as file_upload_router
from backend.healthcheck_router import router as health_router

# å…¨åŸŸè®Šæ•¸å„²å­˜å¾Œå°ä»»å‹™
background_tasks = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç¨‹å¼ç”Ÿå‘½é€±æœŸç®¡ç†"""
    # å•Ÿå‹•æ™‚åŸ·è¡Œ
    print("\n" + "="*60)
    print("ğŸš€ XiaoChenGuang AI System å•Ÿå‹•ä¸­...")
    print("="*60)
    
    # å•Ÿå‹•è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨
    flush_enabled = os.getenv("ENABLE_MEMORY_FLUSH", "true").lower() == "true"
    
    if flush_enabled:
        try:
            from backend.modules.memory.core import MemoryCore
            from backend.jobs.memory_flush_worker import create_flush_worker
            
            memory_core = MemoryCore()
            flush_interval = int(os.getenv("MEMORY_FLUSH_INTERVAL", "300"))
            worker = create_flush_worker(memory_core, interval_seconds=flush_interval)
            
            # åœ¨èƒŒæ™¯å•Ÿå‹•å·¥ä½œå™¨
            flush_task = asyncio.create_task(worker.start())
            background_tasks['memory_flush'] = {
                'task': flush_task,
                'worker': worker
            }
            
            print(f"âœ… è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨å·²å•Ÿå‹•ï¼ˆé–“éš”: {flush_interval}ç§’ï¼‰")
        except Exception as e:
            print(f"âš ï¸ è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨å•Ÿå‹•å¤±æ•—: {e}")
    else:
        print("â„¹ï¸ è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨å·²åœç”¨")
    
    print("="*60)
    print("âœ… ç³»çµ±å•Ÿå‹•å®Œæˆ")
    print("="*60 + "\n")
    
    yield
    
    # é—œé–‰æ™‚åŸ·è¡Œ
    print("\n" + "="*60)
    print("ğŸ‘‹ XiaoChenGuang AI System é—œé–‰ä¸­...")
    print("="*60)
    
    # åœæ­¢è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨
    if 'memory_flush' in background_tasks:
        worker_info = background_tasks['memory_flush']
        worker_info['worker'].stop()
        
        try:
            await asyncio.wait_for(worker_info['task'], timeout=5.0)
            print("âœ… è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨å·²åœæ­¢")
        except asyncio.TimeoutError:
            print("âš ï¸ è¨˜æ†¶åˆ·å¯«å·¥ä½œå™¨åœæ­¢è¶…æ™‚ï¼Œå¼·åˆ¶çµ‚æ­¢")
            worker_info['task'].cancel()
    
    print("="*60)
    print("âœ… ç³»çµ±å·²å®‰å…¨é—œé–‰")
    print("="*60 + "\n")

app = FastAPI(lifespan=lifespan)

# âœ… è¨­å®šè·¨ä¾†æºè³‡æºå…±äº«ï¼ˆCORSï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://ai.dreamground.net",   # Cloudflare Pages å‰ç«¯ç¶²å€
        "https://ai2.dreamground.net",  # å¾Œç«¯è‡ªå·±çš„ç¶²å€
        "https://*.pages.dev"           # Cloudflare é è¨­éƒ¨ç½²å­ç¶²åŸŸï¼ˆä¿éšªç”¨ï¼‰
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¨»å†Šå„å€‹ API è·¯ç”±
app.include_router(health_router, prefix="/api")
app.include_router(chat_router, prefix="/api")
app.include_router(memory_router, prefix="/api")
app.include_router(openai_router, prefix="/api")
app.include_router(file_upload_router, prefix="/api")

# æ ¹è·¯ç”±æª¢æŸ¥æ˜¯å¦é‹è¡Œä¸­
@app.get("/")
async def root():
    return {
        "message": "å°æ™¨å…‰ AI éˆé­‚ç³»çµ± Bot",
        "version": "1.0.0",
        "status": "running"
    }

from fastapi.responses import JSONResponse
import datetime

# æ–°å¢æ¸¬è©¦æ—¥æœŸçš„API
@app.get("/api/test-date")
async def test_date():
    now = datetime.datetime.utcnow()  # ç²å–æ¨™æº–çš„ UTC æ™‚é–“
    iso_date = now.isoformat() + "Z"  # æ ¼å¼åŒ–ç‚º ISO æ¨™æº–
    return JSONResponse(content={"timestamp": iso_date})

if __name__ == "__main__":
    import os
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port)
