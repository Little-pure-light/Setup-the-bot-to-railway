"""
XiaoChenGuang é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹ - Streamlit UI V2
å®Œå…¨é‡æ§‹ç‰ˆæœ¬ - è§£æ±ºæ‰€æœ‰å·²çŸ¥å•é¡Œ

ä¿®å¾©å…§å®¹ï¼š
1. âœ… åŠ å…¥ dotenv ç’°å¢ƒè®Šæ•¸è¼‰å…¥
2. âœ… æ‰€æœ‰ dict å­˜å–æ”¹ç”¨ .get()ï¼ˆé˜²æ­¢ KeyErrorï¼‰
3. âœ… å®Œæ•´çš„éŒ¯èª¤è™•ç†å’Œå‹å–„æç¤º
4. âœ… å„ªåŒ– UI å¡ç‰‡é¡¯ç¤º
5. âœ… æ¸¬è©¦ä¸‰å¤§åŠŸèƒ½ï¼ˆè¨˜éŒ„/æœå°‹/èƒŒæ™¯åŒ…ï¼‰
"""

import streamlit as st
import os
from datetime import datetime
from dotenv import load_dotenv

# ============================================
# ç’°å¢ƒè®Šæ•¸è¼‰å…¥ï¼ˆä¿®å¾©å•é¡Œ 1ï¼‰
# ============================================
load_dotenv()  # å¼·åˆ¶è¼‰å…¥ .env æª”æ¡ˆ

# ============================================
# å»¶é²å°å…¥ï¼ˆé¿å…ç’°å¢ƒè®Šæ•¸æœªè¼‰å…¥ï¼‰
# ============================================
try:
    from supabase import create_client, Client
    from openai import OpenAI
except ImportError as e:
    st.error(f"âŒ å¥—ä»¶å°å…¥å¤±æ•—ï¼š{e}")
    st.info("è«‹åŸ·è¡Œï¼špip install supabase openai python-dotenv streamlit")
    st.stop()

# ============================================
# é…ç½®
# ============================================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_ANON_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ============================================
# åˆå§‹åŒ–å®¢æˆ¶ç«¯ï¼ˆåŠ å…¥éŒ¯èª¤è™•ç†ï¼‰
# ============================================
@st.cache_resource
def init_clients():
    """åˆå§‹åŒ– Supabase å’Œ OpenAI å®¢æˆ¶ç«¯"""
    try:
        if not all([SUPABASE_URL, SUPABASE_KEY, OPENAI_API_KEY]):
            missing = []
            if not SUPABASE_URL: missing.append("SUPABASE_URL")
            if not SUPABASE_KEY: missing.append("SUPABASE_ANON_KEY")
            if not OPENAI_API_KEY: missing.append("OPENAI_API_KEY")
            
            raise ValueError(f"ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ï¼š{', '.join(missing)}")
        
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        
        return supabase, openai_client
    
    except Exception as e:
        st.error(f"âŒ å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
        st.stop()

# ============================================
# æ ¸å¿ƒåŠŸèƒ½ï¼ˆåŠ å…¥å®Œæ•´éŒ¯èª¤è™•ç†ï¼‰
# ============================================

def generate_embedding(openai_client: OpenAI, text: str):
    """ç”Ÿæˆæ–‡æœ¬å‘é‡åµŒå…¥"""
    try:
        response = openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text[:8000]  # é™åˆ¶é•·åº¦
        )
        return response.data[0].embedding
    except Exception as e:
        st.error(f"âŒ å‘é‡ç”Ÿæˆå¤±æ•—ï¼š{e}")
        return None

def save_dev_log(
    supabase: Client,
    openai_client: OpenAI,
    phase: str,
    module: str,
    ai_model: str,
    topic: str,
    question: str,
    answer: str,
    tags: list
):
    """å„²å­˜é–‹ç™¼æ—¥èªŒ"""
    try:
        # 1. ç”Ÿæˆæ‘˜è¦
        q_summary = question[:50] + ("..." if len(question) > 50 else "")
        a_summary = answer[:100] + ("..." if len(answer) > 100 else "")
        summary = f"å•ï¼š{q_summary} ç­”ï¼š{a_summary}"
        
        # 2. è¨ˆç®—é‡è¦æ€§
        importance = 0.5
        if phase in ["Phase3", "Phase4", "Phase5"]:
            importance += 0.3
        if len(answer) > 500:
            importance += 0.2
        
        # 3. ç”Ÿæˆå‘é‡
        combined = f"{topic} {question} {answer}"
        embedding = generate_embedding(openai_client, combined)
        
        if not embedding:
            return False, "å‘é‡ç”Ÿæˆå¤±æ•—"
        
        # 4. å„²å­˜è³‡æ–™
        data = {
            "phase": phase,
            "module": module,
            "ai_model": ai_model,
            "topic": topic,
            "user_question": question,
            "ai_response": answer,
            "summary": summary,
            "embedding": embedding,
            "importance_score": min(importance, 1.0),
            "tags": tags
        }
        
        result = supabase.table("dev_logs").insert(data).execute()
        
        # 5. æª¢æŸ¥çµæœï¼ˆä½¿ç”¨ .get() é˜²æ­¢ KeyErrorï¼‰
        if result.data and len(result.data) > 0:
            log_id = result.data[0].get("id", "unknown")
            return True, str(log_id)
        else:
            return False, "è³‡æ–™å„²å­˜å¤±æ•—"
    
    except Exception as e:
        return False, f"å„²å­˜éŒ¯èª¤ï¼š{str(e)}"

def search_dev_logs(supabase: Client, openai_client: OpenAI, query: str, limit: int = 5):
    """æœå°‹é–‹ç™¼æ—¥èªŒ"""
    try:
        # 1. ç”ŸæˆæŸ¥è©¢å‘é‡
        query_embedding = generate_embedding(openai_client, query)
        
        if not query_embedding:
            return []
        
        # 2. å‘¼å« RPC å‡½æ•¸ï¼ˆä¿®æ­£ç‰ˆæœ¬ - åªå‚³éå…©å€‹åƒæ•¸ï¼‰
        result = supabase.rpc(
            "match_dev_logs",
            {
                "query_embedding": query_embedding,
                "match_count": limit
            }
        ).execute()
        
        # 3. è™•ç†çµæœï¼ˆä½¿ç”¨ .get() é˜²æ­¢ KeyErrorï¼‰
        if result.data:
            return [
                {
                    "id": log.get("id"),
                    "created_at": log.get("created_at", ""),
                    "phase": log.get("phase", "æœªçŸ¥"),
                    "module": log.get("module", "æœªçŸ¥"),
                    "ai_model": log.get("ai_model", "æœªçŸ¥"),
                    "topic": log.get("topic", "ç„¡ä¸»é¡Œ"),
                    "user_question": log.get("user_question", ""),
                    "ai_response": log.get("ai_response", ""),
                    "summary": log.get("summary", ""),
                    "similarity": log.get("similarity", 0.0)
                }
                for log in result.data
            ]
        else:
            return []
    
    except Exception as e:
        st.error(f"âŒ æœå°‹éŒ¯èª¤ï¼š{str(e)}")
        return []

def generate_context_pack(supabase: Client, phase=None, module=None):
    """ç”Ÿæˆå°ˆæ¡ˆèƒŒæ™¯åŒ…"""
    try:
        # æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ RPC å‡½æ•¸
        result = supabase.rpc(
            "generate_project_context",
            {
                "target_phase": phase,
                "target_module": module,
                "max_logs": 10
            }
        ).execute()
        
        if result.data:
            return True, result.data
        else:
            # æ–¹æ¡ˆ 2ï¼šæ‰‹å‹•ç”Ÿæˆ
            return manual_generate_context(supabase, phase, module)
    
    except Exception as e:
        # é™ç´šç‚ºæ‰‹å‹•ç”Ÿæˆ
        return manual_generate_context(supabase, phase, module)

def manual_generate_context(supabase: Client, phase=None, module=None):
    """æ‰‹å‹•ç”ŸæˆèƒŒæ™¯åŒ…ï¼ˆé™ç´šæ–¹æ¡ˆï¼‰"""
    try:
        # æŸ¥è©¢æœ€è¿‘è¨˜éŒ„
        query = supabase.table("dev_logs").select("*")
        
        if phase:
            query = query.eq("phase", phase)
        if module:
            query = query.eq("module", module)
        
        result = query.order("created_at", desc=True).limit(10).execute()
        logs = result.data or []
        
        # çµ„åˆæ–‡æœ¬
        context = f"""ğŸ“¦ XiaoChenGuang å°ˆæ¡ˆèƒŒæ™¯åŒ…
ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€å°ˆæ¡ˆæ¦‚è¿°ã€‘
æ•¸ä½éˆé­‚å­µåŒ–å™¨ - XiaoChenGuang AI ç³»çµ±
æŠ€è¡“æ£§ï¼šFastAPI + Vue 3 + Supabase + OpenAI + Redis
æ ¸å¿ƒæ¨¡çµ„ï¼š
  â€¢ è¨˜æ†¶ç³»çµ±ï¼ˆå‘é‡åµŒå…¥ + pgvectorï¼‰
  â€¢ åæ€æ¨¡çµ„ï¼ˆåæ¨æœå› æ³•å‰‡ï¼‰
  â€¢ äººæ ¼å­¸ç¿’å¼•æ“ï¼ˆå‹•æ…‹ç‰¹è³ªèª¿æ•´ï¼‰
  â€¢ æƒ…æ„Ÿæª¢æ¸¬ç³»çµ±ï¼ˆ9ç¨®æƒ…ç·’é¡å‹ï¼‰
  â€¢ æç¤ºè©å¼•æ“ï¼ˆå‹•æ…‹ Prompt ç”Ÿæˆï¼‰

ã€æœ€è¿‘é–‹ç™¼è¨˜éŒ„ã€‘
"""
        
        if logs:
            for i, log in enumerate(logs, 1):
                date = log.get("created_at", "")[:10]
                phase_tag = log.get("phase", "æœªçŸ¥")
                topic = log.get("topic", "ç„¡ä¸»é¡Œ")
                summary = log.get("summary", "")[:80]
                
                context += f"{i}. {date} [{phase_tag}] {topic}\n"
                context += f"   æ‘˜è¦ï¼š{summary}...\n\n"
        else:
            context += "ï¼ˆç›®å‰å°šç„¡é–‹ç™¼è¨˜éŒ„ï¼‰\n\n"
        
        context += """ã€ä½¿ç”¨èªªæ˜ã€‘
1. è¤‡è£½ä¸Šé¢çš„èƒŒæ™¯åŒ…
2. è²¼çµ¦ä»»ä½• AIï¼ˆChatGPT/Claude/Geminiï¼‰
3. AI å°±èƒ½ç«‹åˆ»äº†è§£å°ˆæ¡ˆèƒŒæ™¯ï¼
4. ç„¶å¾Œå•ä½ çš„å•é¡Œï¼ŒAI æœƒçµ¦å‡ºæ›´ç²¾æº–çš„å»ºè­°

---
ç”± XiaoChenGuang é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹ç”Ÿæˆ
"""
        return True, context
    
    except Exception as e:
        return False, f"âŒ èƒŒæ™¯åŒ…ç”Ÿæˆå¤±æ•—ï¼š{e}"

# ============================================
# Streamlit UI
# ============================================

def main():
    st.set_page_config(
        page_title="ğŸ§  XiaoChenGuang é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹",
        page_icon="ğŸ§ ",
        layout="wide"
    )
    
    # è‡ªè¨‚ CSSï¼ˆå„ªåŒ–è¦–è¦ºæ•ˆæœï¼‰
    st.markdown("""
    <style>
    .big-font {
        font-size: 20px !important;
        font-weight: bold;
    }
    .card {
        padding: 20px;
        border-radius: 10px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        margin-bottom: 20px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ğŸ§  XiaoChenGuang é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹")
    st.markdown("**è®“ä½ çš„ AI ä¸å†å¤±æ†¶ï¼å¿«é€Ÿè¨˜éŒ„é–‹ç™¼å°è©±ï¼Œä¸€éµå–šé†’ AI è¨˜æ†¶**")
    
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    if not all([SUPABASE_URL, SUPABASE_KEY, OPENAI_API_KEY]):
        st.error("âš ï¸ ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ï¼")
        st.info("""
        è«‹åœ¨ Replit Secrets ä¸­è¨­å®šï¼š
        - SUPABASE_URL
        - SUPABASE_ANON_KEY
        - OPENAI_API_KEY
        """)
        st.stop()
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    supabase, openai_client = init_clients()
    
    # å´é‚Šæ¬„
    st.sidebar.title("ğŸ¯ åŠŸèƒ½é¸å–®")
    mode = st.sidebar.radio(
        "é¸æ“‡åŠŸèƒ½",
        ["ğŸ“ å¿«é€Ÿè¨˜éŒ„", "ğŸ” æœå°‹è¨˜æ†¶", "ğŸ“¦ ç”ŸæˆèƒŒæ™¯åŒ…"],
        label_visibility="collapsed"
    )
    
    st.sidebar.markdown("---")
    st.sidebar.caption("ğŸŒŒ XiaoChenGuang éˆé­‚å­µåŒ–å™¨")
    st.sidebar.caption("è®“ AI è¨˜ä½ä½ çš„é–‹ç™¼æ­·ç¨‹")
    
    # ============================================
    # åŠŸèƒ½ 1ï¼šå¿«é€Ÿè¨˜éŒ„
    # ============================================
    if mode == "ğŸ“ å¿«é€Ÿè¨˜éŒ„":
        st.header("ğŸ“ å¿«é€Ÿè¨˜éŒ„é–‹ç™¼å°è©±")
        st.markdown("è·Ÿ AI è¨è«–å®Œå°ˆæ¡ˆå¾Œï¼Œç«‹åˆ»è¨˜éŒ„é‡é»ï¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            phase = st.selectbox(
                "éšæ®µ",
                ["Phase1", "Phase2", "Phase3", "Phase4", "Phase5", "å…¶ä»–"]
            )
            
            module = st.selectbox(
                "æ¨¡çµ„",
                ["è¨˜æ†¶æ¨¡çµ„", "åæ€æ¨¡çµ„", "è¡Œç‚ºèª¿ç¯€æ¨¡çµ„", "çŸ¥è­˜åº«", "å¾®èª¿æ¨¡çµ„", "æƒ…æ„Ÿæª¢æ¸¬", "æç¤ºè©å¼•æ“", "é€šç”¨"]
            )
        
        with col2:
            ai_model = st.selectbox(
                "AI æ¨¡å‹",
                ["GPT-4", "GPT-4o", "GPT-4o-mini", "Claude-3.5-Sonnet", "Claude-3-Opus", "Gemini-Pro", "Gemini-Flash", "å…¶ä»–"]
            )
            
            topic = st.text_input("è¨è«–ä¸»é¡Œ", placeholder="ä¾‹å¦‚ï¼šåæ€å¾ªç’°æ¸¬è©¦æ–¹æ³•")
        
        question = st.text_area(
            "ä½ çš„å•é¡Œ",
            placeholder="ä½ å• AI çš„å•é¡Œ...",
            height=150
        )
        
        answer = st.text_area(
            "AI çš„å›ç­”",
            placeholder="AI çµ¦ä½ çš„å›ç­”...",
            height=250
        )
        
        tags_input = st.text_input(
            "æ¨™ç±¤ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼Œå¯é¸ï¼‰",
            placeholder="æ¸¬è©¦,bugä¿®å¾©,Phase3"
        )
        
        if st.button("ğŸ’¾ å„²å­˜è¨˜éŒ„", type="primary", use_container_width=True):
            # é©—è­‰è¼¸å…¥
            if not all([topic, question, answer]):
                st.error("âŒ è«‹å¡«å¯«æ‰€æœ‰å¿…å¡«æ¬„ä½ï¼ˆä¸»é¡Œã€å•é¡Œã€å›ç­”ï¼‰ï¼")
            else:
                tags = [t.strip() for t in tags_input.split(",")] if tags_input else []
                
                with st.spinner("å„²å­˜ä¸­..."):
                    success, result = save_dev_log(
                        supabase, openai_client, phase, module, ai_model,
                        topic, question, answer, tags
                    )
                
                if success:
                    st.success(f"âœ… å„²å­˜æˆåŠŸï¼è¨˜éŒ„ ID: {result}")
                    st.balloons()
                else:
                    st.error(f"âŒ å„²å­˜å¤±æ•—ï¼š{result}")
    
    # ============================================
    # åŠŸèƒ½ 2ï¼šæœå°‹è¨˜æ†¶
    # ============================================
    elif mode == "ğŸ” æœå°‹è¨˜æ†¶":
        st.header("ğŸ” æœå°‹é–‹ç™¼è¨˜æ†¶")
        st.markdown("ç”¨é—œéµå­—æˆ–å•é¡Œæœå°‹ç›¸é—œçš„é–‹ç™¼è¨˜éŒ„")
        
        query = st.text_input(
            "æœå°‹å•é¡Œ",
            placeholder="ä¾‹å¦‚ï¼šåæ€æ¨¡çµ„å¦‚ä½•æ¸¬è©¦ï¼Ÿ",
            key="search_query"
        )
        
        col1, col2 = st.columns([3, 1])
        with col1:
            limit = st.slider("è¿”å›æ•¸é‡", 1, 10, 5)
        with col2:
            search_button = st.button("ğŸ” æœå°‹", type="primary", use_container_width=True)
        
        if search_button:
            if not query:
                st.error("âŒ è«‹è¼¸å…¥æœå°‹å•é¡Œï¼")
            else:
                with st.spinner("æœå°‹ä¸­..."):
                    results = search_dev_logs(supabase, openai_client, query, limit)
                
                if results:
                    st.success(f"âœ… æ‰¾åˆ° {len(results)} æ¢ç›¸é—œè¨˜éŒ„")
                    
                    for i, log in enumerate(results, 1):
                        # å®‰å…¨å–å€¼ï¼ˆä½¿ç”¨ .get()ï¼‰
                        topic = log.get("topic", "ç„¡ä¸»é¡Œ")
                        phase = log.get("phase", "æœªçŸ¥")
                        similarity = log.get("similarity", 0.0)
                        date = log.get("created_at", "")[:10]
                        module = log.get("module", "æœªçŸ¥")
                        ai_model = log.get("ai_model", "æœªçŸ¥")
                        summary = log.get("summary", "")
                        user_q = log.get("user_question", "")
                        ai_a = log.get("ai_response", "")
                        
                        # å¡ç‰‡å¼é¡¯ç¤ºï¼ˆå„ªåŒ– UIï¼‰
                        with st.expander(
                            f"ğŸ“Œ {i}. {topic} ({phase}) - ç›¸ä¼¼åº¦: {similarity:.2%}",
                            expanded=(i == 1)  # ç¬¬ä¸€æ¢é è¨­å±•é–‹
                        ):
                            col_a, col_b, col_c = st.columns(3)
                            with col_a:
                                st.caption(f"ğŸ“… æ—¥æœŸï¼š{date}")
                            with col_b:
                                st.caption(f"ğŸ§© æ¨¡çµ„ï¼š{module}")
                            with col_c:
                                st.caption(f"ğŸ¤– AIï¼š{ai_model}")
                            
                            st.markdown("---")
                            
                            if summary:
                                st.info(f"ğŸ“ æ‘˜è¦ï¼š{summary}")
                            
                            st.markdown("**ğŸ’¬ å•é¡Œï¼š**")
                            st.code(user_q, language=None)
                            
                            st.markdown("**âœ¨ å›ç­”ï¼š**")
                            st.code(ai_a, language=None)
                else:
                    st.warning("âš ï¸ æœªæ‰¾åˆ°ç›¸é—œè¨˜éŒ„")
    
    # ============================================
    # åŠŸèƒ½ 3ï¼šç”ŸæˆèƒŒæ™¯åŒ…
    # ============================================
    elif mode == "ğŸ“¦ ç”ŸæˆèƒŒæ™¯åŒ…":
        st.header("ğŸ“¦ ç”Ÿæˆ AI è¨˜æ†¶å–šé†’åŒ…")
        st.markdown("ä¸€éµç”Ÿæˆå°ˆæ¡ˆèƒŒæ™¯æ‘˜è¦ï¼Œè²¼çµ¦æ–° AI ç«‹åˆ»å–šé†’è¨˜æ†¶ï¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            filter_phase = st.selectbox(
                "ç¯©é¸éšæ®µï¼ˆå¯é¸ï¼‰",
                ["å…¨éƒ¨", "Phase1", "Phase2", "Phase3", "Phase4", "Phase5"]
            )
        
        with col2:
            filter_module = st.selectbox(
                "ç¯©é¸æ¨¡çµ„ï¼ˆå¯é¸ï¼‰",
                ["å…¨éƒ¨", "è¨˜æ†¶æ¨¡çµ„", "åæ€æ¨¡çµ„", "è¡Œç‚ºèª¿ç¯€æ¨¡çµ„", "çŸ¥è­˜åº«", "å…¶ä»–"]
            )
        
        if st.button("ğŸš€ ç”ŸæˆèƒŒæ™¯åŒ…", type="primary", use_container_width=True):
            with st.spinner("ç”Ÿæˆä¸­..."):
                phase = None if filter_phase == "å…¨éƒ¨" else filter_phase
                module = None if filter_module == "å…¨éƒ¨" else filter_module
                
                success, context = generate_context_pack(supabase, phase, module)
            
            if success:
                st.success("âœ… ç”Ÿæˆå®Œæˆï¼")
                st.markdown("---")
                st.markdown("### ğŸ“‹ è¤‡è£½ä¸‹é¢çš„èƒŒæ™¯åŒ…ï¼Œè²¼çµ¦ä»»ä½• AIï¼š")
                
                st.text_area(
                    "å°ˆæ¡ˆèƒŒæ™¯åŒ…",
                    value=context,
                    height=500,
                    key="context_pack"
                )
                
                st.info("ğŸ’¡ **ä½¿ç”¨æ–¹å¼ï¼š** è¤‡è£½ä¸Šé¢çš„æ–‡å­— â†’ è²¼çµ¦ ChatGPT/Claude/Gemini â†’ AI å°±èƒ½è¨˜èµ·ä½ çš„å°ˆæ¡ˆäº†ï¼")
            else:
                st.error(f"âŒ {context}")
    
    # é å°¾
    st.markdown("---")
    st.caption("ğŸŒŒ ç”± XiaoChenGuang éˆé­‚å­µåŒ–å™¨æä¾›æ”¯æ´ | V2.0 é‡æ§‹ç‰ˆ")


if __name__ == "__main__":
    main()
