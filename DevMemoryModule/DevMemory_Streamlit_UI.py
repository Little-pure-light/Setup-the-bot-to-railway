"""
é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹ - Streamlit ç°¡æ˜“ä»‹é¢
ç”¨é€”ï¼šå¿«é€Ÿè¨˜éŒ„é–‹ç™¼å°è©± + ç”Ÿæˆ AI èƒŒæ™¯åŒ…
ä½ç½®ï¼šå¯ä»¥æ”¾åœ¨ SemanticMemoryUploaderMini/dev_memory_helper.py

å®Œç¾å¥‘åˆï¼š
- ä½¿ç”¨ä½ ç¾æœ‰çš„ Supabase é€£æ¥
- ä½¿ç”¨ä½ ç¾æœ‰çš„ OpenAI API
- å¯ä»¥è·Ÿç¾æœ‰çš„ Streamlit ä¸Šå‚³å™¨æ•´åˆ
"""

import streamlit as st
import os
from datetime import datetime
from supabase import create_client
import openai

# ============================================
# é…ç½®
# ============================================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_ANON_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ============================================
# åˆå§‹åŒ–
# ============================================
@st.cache_resource
def init_clients():
    """åˆå§‹åŒ– Supabase å’Œ OpenAI å®¢æˆ¶ç«¯"""
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    openai.api_key = OPENAI_API_KEY
    return supabase

# ============================================
# æ ¸å¿ƒåŠŸèƒ½
# ============================================

def generate_embedding(text: str):
    """ç”Ÿæˆæ–‡æœ¬å‘é‡åµŒå…¥"""
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def save_dev_log(supabase, phase, module, ai_model, topic, question, answer, tags):
    """å„²å­˜é–‹ç™¼æ—¥èªŒ"""
    try:
        # ç”Ÿæˆæ‘˜è¦
        q_summary = question[:50] + ("..." if len(question) > 50 else "")
        a_summary = answer[:100] + ("..." if len(answer) > 100 else "")
        summary = f"å•ï¼š{q_summary} ç­”ï¼š{a_summary}"
        
        # è¨ˆç®—é‡è¦æ€§
        importance = 0.5
        if phase in ["Phase3", "Phase4"]:
            importance += 0.3
        if len(answer) > 500:
            importance += 0.2
        
        # ç”Ÿæˆå‘é‡
        combined = f"{topic} {question} {answer}"
        embedding = generate_embedding(combined)
        
        # å„²å­˜
        data = {
            "phase": phase,
            "module": module,
            "ai_model": ai_model,
            "topic": topic,
            "user_question": question,
            "ai_response": answer,
            "summary": summary,
            "embedding": embedding,
            "importance_score": min(importance, 1.0),
            "tags": tags
        }
        
        result = supabase.table("dev_logs").insert(data).execute()
        return True, result.data[0]["id"]
    
    except Exception as e:
        return False, str(e)

def search_dev_logs(supabase, query, limit=5):
    """æœå°‹é–‹ç™¼æ—¥èªŒ"""
    try:
        # ç”ŸæˆæŸ¥è©¢å‘é‡
        query_embedding = generate_embedding(query)
        
        # å‘¼å« RPC å‡½æ•¸
        result = supabase.rpc(
            "match_dev_logs",
            {
                "query_embedding": query_embedding,
                "match_count": limit
            }
        ).execute()
        
        return result.data
    except Exception as e:
        st.error(f"æœå°‹éŒ¯èª¤ï¼š{e}")
        return []

def generate_context_pack(supabase, phase=None, module=None):
    """ç”Ÿæˆå°ˆæ¡ˆèƒŒæ™¯åŒ…"""
    try:
        # æŸ¥è©¢æœ€è¿‘è¨˜éŒ„
        query = supabase.table("dev_logs").select("*")
        
        if phase:
            query = query.eq("phase", phase)
        if module:
            query = query.eq("module", module)
        
        result = query.order("created_at", desc=True).limit(10).execute()
        logs = result.data
        
        # çµ„åˆæ–‡æœ¬
        context = f"""ğŸ“¦ XiaoChenGuang å°ˆæ¡ˆèƒŒæ™¯åŒ…
ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}

ã€å°ˆæ¡ˆæ¦‚è¿°ã€‘
æ•¸ä½éˆé­‚å­µåŒ–å™¨ - XiaoChenGuang AI ç³»çµ±
æŠ€è¡“æ£§ï¼šFastAPI + Vue 3 + Supabase + OpenAI
æ ¸å¿ƒæ¨¡çµ„ï¼š
- è¨˜æ†¶ç³»çµ±ï¼ˆå‘é‡åµŒå…¥ + pgvector + Redisï¼‰
- åæ€æ¨¡çµ„ï¼ˆåæ¨æœå› æ³•å‰‡ï¼‰
- äººæ ¼å­¸ç¿’å¼•æ“ï¼ˆå‹•æ…‹ç‰¹è³ªèª¿æ•´ï¼‰
- æƒ…æ„Ÿæª¢æ¸¬ç³»çµ±ï¼ˆ9ç¨®æƒ…ç·’é¡å‹ï¼‰
- æç¤ºè©å¼•æ“ï¼ˆå‹•æ…‹ Prompt ç”Ÿæˆï¼‰

ã€æœ€è¿‘é–‹ç™¼è¨˜éŒ„ã€‘
"""
        
        for log in logs:
            date = log["created_at"][:10]
            phase_tag = log.get("phase", "é€šç”¨")
            topic = log.get("topic", "ç„¡ä¸»é¡Œ")
            summary = log.get("summary", "")[:80]
            
            context += f"- {date} [{phase_tag}] {topic}\n"
            context += f"  {summary}...\n"
        
        context += """
ã€ä½¿ç”¨èªªæ˜ã€‘
1. è¤‡è£½ä¸Šé¢çš„èƒŒæ™¯åŒ…
2. è²¼çµ¦ä»»ä½• AIï¼ˆChatGPT/Claude/Geminiï¼‰
3. AI å°±èƒ½ç«‹åˆ»äº†è§£å°ˆæ¡ˆèƒŒæ™¯ï¼
4. ç„¶å¾Œå•ä½ çš„å•é¡Œï¼ŒAI æœƒçµ¦å‡ºæ›´ç²¾æº–çš„å»ºè­°

---
ç”± XiaoChenGuang é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹ç”Ÿæˆ
"""
        return context
    
    except Exception as e:
        return f"ç”ŸæˆéŒ¯èª¤ï¼š{e}"

# ============================================
# Streamlit UI
# ============================================

def main():
    st.set_page_config(
        page_title="ğŸ§  é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹",
        page_icon="ğŸ§ ",
        layout="wide"
    )
    
    st.title("ğŸ§  XiaoChenGuang é–‹ç™¼è€…è¨˜æ†¶åŠ©æ‰‹")
    st.markdown("**è®“ä½ çš„ AI ä¸å†å¤±æ†¶ï¼å¿«é€Ÿè¨˜éŒ„é–‹ç™¼å°è©±ï¼Œä¸€éµå–šé†’ AI è¨˜æ†¶**")
    
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    if not all([SUPABASE_URL, SUPABASE_KEY, OPENAI_API_KEY]):
        st.error("âš ï¸ ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ï¼è«‹è¨­å®š SUPABASE_URL, SUPABASE_ANON_KEY, OPENAI_API_KEY")
        return
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    supabase = init_clients()
    
    # å´é‚Šæ¬„ï¼šåŠŸèƒ½é¸æ“‡
    st.sidebar.title("ğŸ¯ åŠŸèƒ½é¸å–®")
    mode = st.sidebar.radio(
        "é¸æ“‡åŠŸèƒ½",
        ["ğŸ“ å¿«é€Ÿè¨˜éŒ„", "ğŸ” æœå°‹è¨˜æ†¶", "ğŸ“¦ ç”ŸæˆèƒŒæ™¯åŒ…"]
    )
    
    # ============================================
    # åŠŸèƒ½ 1ï¼šå¿«é€Ÿè¨˜éŒ„
    # ============================================
    if mode == "ğŸ“ å¿«é€Ÿè¨˜éŒ„":
        st.header("ğŸ“ å¿«é€Ÿè¨˜éŒ„é–‹ç™¼å°è©±")
        st.markdown("è·Ÿ AI è¨è«–å®Œå°ˆæ¡ˆå¾Œï¼Œç«‹åˆ»è¨˜éŒ„é‡é»ï¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            phase = st.selectbox(
                "éšæ®µ",
                ["Phase1", "Phase2", "Phase3", "Phase4", "Phase5", "å…¶ä»–"]
            )
            
            module = st.selectbox(
                "æ¨¡çµ„",
                ["è¨˜æ†¶æ¨¡çµ„", "åæ€æ¨¡çµ„", "è¡Œç‚ºèª¿ç¯€æ¨¡çµ„", "çŸ¥è­˜åº«", "å¾®èª¿æ¨¡çµ„", "æƒ…æ„Ÿæª¢æ¸¬", "æç¤ºè©å¼•æ“", "é€šç”¨"]
            )
        
        with col2:
            ai_model = st.selectbox(
                "AI æ¨¡å‹",
                ["GPT-4", "GPT-4o", "Claude-3.5", "Claude-3", "Gemini-Pro", "å…¶ä»–"]
            )
            
            topic = st.text_input("è¨è«–ä¸»é¡Œ", placeholder="ä¾‹å¦‚ï¼šåæ€å¾ªç’°æ¸¬è©¦æ–¹æ³•")
        
        question = st.text_area(
            "ä½ çš„å•é¡Œ",
            placeholder="ä½ å• AI çš„å•é¡Œ...",
            height=100
        )
        
        answer = st.text_area(
            "AI çš„å›ç­”",
            placeholder="AI çµ¦ä½ çš„å›ç­”...",
            height=200
        )
        
        tags_input = st.text_input(
            "æ¨™ç±¤ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼‰",
            placeholder="æ¸¬è©¦,bugä¿®å¾©,Phase3"
        )
        
        if st.button("ğŸ’¾ å„²å­˜è¨˜éŒ„", type="primary", use_container_width=True):
            if not all([topic, question, answer]):
                st.error("è«‹å¡«å¯«æ‰€æœ‰å¿…å¡«æ¬„ä½ï¼")
            else:
                tags = [t.strip() for t in tags_input.split(",")] if tags_input else []
                
                with st.spinner("å„²å­˜ä¸­..."):
                    success, result = save_dev_log(
                        supabase, phase, module, ai_model, 
                        topic, question, answer, tags
                    )
                
                if success:
                    st.success(f"âœ… å„²å­˜æˆåŠŸï¼è¨˜éŒ„ ID: {result}")
                    st.balloons()
                else:
                    st.error(f"âŒ å„²å­˜å¤±æ•—ï¼š{result}")
    
    # ============================================
    # åŠŸèƒ½ 2ï¼šæœå°‹è¨˜æ†¶
    # ============================================
    elif mode == "ğŸ” æœå°‹è¨˜æ†¶":
        st.header("ğŸ” æœå°‹é–‹ç™¼è¨˜æ†¶")
        st.markdown("ç”¨é—œéµå­—æˆ–å•é¡Œæœå°‹ç›¸é—œçš„é–‹ç™¼è¨˜éŒ„")
        
        query = st.text_input(
            "æœå°‹å•é¡Œ",
            placeholder="ä¾‹å¦‚ï¼šåæ€æ¨¡çµ„å¦‚ä½•æ¸¬è©¦ï¼Ÿ",
            key="search_query"
        )
        
        col1, col2 = st.columns([3, 1])
        with col1:
            limit = st.slider("è¿”å›æ•¸é‡", 1, 10, 5)
        with col2:
            if st.button("ğŸ” æœå°‹", type="primary", use_container_width=True):
                if query:
                    with st.spinner("æœå°‹ä¸­..."):
                        results = search_dev_logs(supabase, query, limit)
                    
                    if results:
                        st.success(f"æ‰¾åˆ° {len(results)} æ¢ç›¸é—œè¨˜éŒ„")
                        
                        for i, log in enumerate(results, 1):
                            with st.expander(f"ğŸ“Œ {i}. {log['topic']} ({log['phase']}) - ç›¸ä¼¼åº¦: {log['similarity']:.2%}"):
                                st.markdown(f"**æ—¥æœŸï¼š** {log['created_at'][:10]}")
                                st.markdown(f"**æ¨¡çµ„ï¼š** {log['module']}")
                                st.markdown(f"**æ‘˜è¦ï¼š** {log['summary']}")
                                
                                st.markdown("---")
                                st.markdown("**å•é¡Œï¼š**")
                                st.info(log['user_question'])
                                
                                st.markdown("**å›ç­”ï¼š**")
                                st.success(log['ai_response'])
                                
                                # ä¸€éµè¤‡è£½
                                copy_text = f"å•ï¼š{log['user_question']}\n\nç­”ï¼š{log['ai_response']}"
                                st.code(copy_text, language=None)
                    else:
                        st.warning("æ²’æœ‰æ‰¾åˆ°ç›¸é—œè¨˜éŒ„")
                else:
                    st.error("è«‹è¼¸å…¥æœå°‹å•é¡Œï¼")
    
    # ============================================
    # åŠŸèƒ½ 3ï¼šç”ŸæˆèƒŒæ™¯åŒ…
    # ============================================
    elif mode == "ğŸ“¦ ç”ŸæˆèƒŒæ™¯åŒ…":
        st.header("ğŸ“¦ ç”Ÿæˆ AI è¨˜æ†¶å–šé†’åŒ…")
        st.markdown("ä¸€éµç”Ÿæˆå°ˆæ¡ˆèƒŒæ™¯æ‘˜è¦ï¼Œè²¼çµ¦æ–° AI ç«‹åˆ»å–šé†’è¨˜æ†¶ï¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            filter_phase = st.selectbox(
                "ç¯©é¸éšæ®µï¼ˆå¯é¸ï¼‰",
                ["å…¨éƒ¨", "Phase1", "Phase2", "Phase3", "Phase4", "Phase5"]
            )
        
        with col2:
            filter_module = st.selectbox(
                "ç¯©é¸æ¨¡çµ„ï¼ˆå¯é¸ï¼‰",
                ["å…¨éƒ¨", "è¨˜æ†¶æ¨¡çµ„", "åæ€æ¨¡çµ„", "è¡Œç‚ºèª¿ç¯€æ¨¡çµ„", "çŸ¥è­˜åº«", "å…¶ä»–"]
            )
        
        if st.button("ğŸš€ ç”ŸæˆèƒŒæ™¯åŒ…", type="primary", use_container_width=True):
            with st.spinner("ç”Ÿæˆä¸­..."):
                phase = None if filter_phase == "å…¨éƒ¨" else filter_phase
                module = None if filter_module == "å…¨éƒ¨" else filter_module
                
                context = generate_context_pack(supabase, phase, module)
            
            st.success("âœ… ç”Ÿæˆå®Œæˆï¼")
            st.markdown("---")
            st.markdown("### ğŸ“‹ è¤‡è£½ä¸‹é¢çš„èƒŒæ™¯åŒ…ï¼Œè²¼çµ¦ä»»ä½• AIï¼š")
            
            st.text_area(
                "å°ˆæ¡ˆèƒŒæ™¯åŒ…",
                value=context,
                height=400,
                key="context_pack"
            )
            
            st.info("ğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼šè¤‡è£½ä¸Šé¢çš„æ–‡å­— â†’ è²¼çµ¦ ChatGPT/Claude/Gemini â†’ AI å°±èƒ½è¨˜èµ·ä½ çš„å°ˆæ¡ˆäº†ï¼")
    
    # é å°¾
    st.markdown("---")
    st.caption("ğŸŒŒ ç”± XiaoChenGuang éˆé­‚å­µåŒ–å™¨æä¾›æ”¯æ´ | è®“ AI è¨˜ä½ä½ çš„é–‹ç™¼æ­·ç¨‹")


if __name__ == "__main__":
    main()
