"""
Copilot Memory Integration
æ•´åˆå°å®¸å…‰è¨˜æ†¶ç³»çµ±ï¼Œæä¾›çµ¦ Copilot ä½¿ç”¨
"""

import json
import logging
from typing import List, Dict, Optional
from datetime import datetime
import sys
import os

project_root = os.path.join(os.path.dirname(__file__), '../../..')
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from backend.openai_handler import get_openai_client
from config import config

logger = logging.getLogger("copilot_memory")

class CopilotMemoryIntegration:
    """Copilot è¨˜æ†¶æ•´åˆé¡åˆ¥"""
    
    def __init__(self, redis_interface, supabase_client):
        self.redis = redis_interface
        self.supabase = supabase_client
        self.openai_client = get_openai_client()
    
    async def get_recent_memories(
        self,
        conversation_id: Optional[str] = None,
        limit: int = 5
    ) -> List[Dict]:
        """
        å¾å…±ç”¨è³‡æ–™åº«å–å¾—æœ€è¿‘çš„è¨˜æ†¶
        
        åƒæ•¸:
            conversation_id: å°è©± IDï¼ˆå¯é¸ï¼‰
            limit: è¿”å›æ•¸é‡
        
        è¿”å›:
            è¨˜æ†¶åˆ—è¡¨
        """
        try:
            query = self.supabase.table(config.SUPABASE_MEMORIES_TABLE).select("*")
            
            if conversation_id:
                query = query.eq("conversation_id", conversation_id)
            
            response = query.order("created_at", desc=True).limit(limit).execute()
            
            memories = response.data if response.data else []
            logger.info(f"ğŸ“¥ å–å¾— {len(memories)} ç­†è¨˜æ†¶")
            
            return memories
            
        except Exception as e:
            logger.error(f"âŒ å–å¾—è¨˜æ†¶å¤±æ•—: {e}")
            return []
    
    async def get_personality_traits(self) -> Dict:
        """
        å–å¾—æœ€æ–°çš„äººæ ¼ç‰¹è³ª
        
        è¿”å›:
            äººæ ¼ç‰¹è³ªå­—å…¸
        """
        try:
            response = self.supabase.table(config.SUPABASE_PERSONALITY_TABLE).select(
                "*"
            ).order("created_at", desc=True).limit(1).execute()
            
            if response.data:
                personality = response.data[0]
                logger.info(f"ğŸŒˆ å–å¾—äººæ ¼ç‰¹è³ª: {personality.get('trait', 'default')}")
                return personality
            
            return {"trait": "analytical", "description": "é è¨­åˆ†æå‹äººæ ¼"}
            
        except Exception as e:
            logger.error(f"âŒ å–å¾—äººæ ¼ç‰¹è³ªå¤±æ•—: {e}")
            return {"trait": "default", "description": "é è¨­äººæ ¼"}
    
    def build_enhanced_prompt(
        self,
        user_prompt: str,
        recent_memories: List[Dict],
        personality: Dict,
        file_name: Optional[str] = None,
        file_context: Optional[str] = None
    ) -> str:
        """
        çµ„åˆå¢å¼·çš„ promptï¼ŒåŒ…å«è¨˜æ†¶ä¸Šä¸‹æ–‡èˆ‡äººæ ¼
        
        åƒæ•¸:
            user_prompt: ç”¨æˆ¶åŸå§‹æç¤º
            recent_memories: æœ€è¿‘è¨˜æ†¶
            personality: äººæ ¼ç‰¹è³ª
            file_name: æª”æ¡ˆåç¨±
            file_context: æª”æ¡ˆä¸Šä¸‹æ–‡
        
        è¿”å›:
            å¢å¼·å¾Œçš„ prompt
        """
        
        # å»ºæ§‹è¨˜æ†¶ä¸Šä¸‹æ–‡
        memory_context = ""
        if recent_memories:
            memory_context = "### ç›¸é—œæ­·å²è¨˜æ†¶\n"
            for i, mem in enumerate(recent_memories[:3], 1):
                user_msg = mem.get("user_message", "")[:100]
                assistant_msg = mem.get("assistant_message", "")[:100]
                memory_context += f"{i}. ç”¨æˆ¶: {user_msg}\n   åŠ©æ‰‹: {assistant_msg}\n\n"
        
        # å»ºæ§‹äººæ ¼æŒ‡å¼•
        personality_guide = f"""### äººæ ¼ç‰¹è³ª
ç•¶å‰äººæ ¼: {personality.get('trait', 'analytical')}
æè¿°: {personality.get('description', 'å°ˆæ¥­ä¸”å‹å–„çš„åŠ©æ‰‹')}
"""
        
        # å»ºæ§‹æª”æ¡ˆä¸Šä¸‹æ–‡
        file_section = ""
        if file_name or file_context:
            file_section = "### æª”æ¡ˆä¸Šä¸‹æ–‡\n"
            if file_name:
                file_section += f"æª”æ¡ˆåç¨±: {file_name}\n"
            if file_context:
                file_section += f"å…§å®¹æ‘˜è¦: {file_context[:500]}\n"
            file_section += "\n"
        
        # çµ„åˆå®Œæ•´ prompt
        enhanced_prompt = f"""
{personality_guide}

{memory_context}

{file_section}

### ç”¨æˆ¶è«‹æ±‚
{user_prompt}

è«‹æ ¹æ“šä»¥ä¸Šè¨˜æ†¶èˆ‡äººæ ¼ç‰¹è³ªï¼Œæä¾›å°ˆæ¥­ä¸”å‹å–„çš„å›æ‡‰ã€‚
"""
        
        return enhanced_prompt
    
    async def simulate_copilot_response(self, enhanced_prompt: str) -> str:
        """
        æ¨¡æ“¬ Copilot å›è¦†ï¼ˆæœªä¾†æ›¿æ›ç‚ºçœŸå¯¦ Copilot APIï¼‰
        
        åƒæ•¸:
            enhanced_prompt: å¢å¼·å¾Œçš„ prompt
        
        è¿”å›:
            æ¨¡æ“¬å›è¦†
        """
        try:
            # ä½¿ç”¨ OpenAI API æ¨¡æ“¬ Copilot å›è¦†
            response = self.openai_client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¨‹å¼è¨­è¨ˆåŠ©æ‰‹ï¼Œåƒ GitHub Copilot ä¸€æ¨£æä¾›ç¨‹å¼ç¢¼å»ºè­°å’ŒæŠ€è¡“æŒ‡å°ã€‚"
                    },
                    {
                        "role": "user",
                        "content": enhanced_prompt
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            reply = response.choices[0].message.content
            logger.info(f"ğŸ¤– æ¨¡æ“¬ Copilot å›è¦†å·²ç”Ÿæˆ")
            
            return reply
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå›è¦†å¤±æ•—: {e}")
            return "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•ç”Ÿæˆå›è¦†ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"
    
    async def save_copilot_memory(
        self,
        conversation_id: str,
        user_id: str,
        session_id: str,
        user_prompt: str,
        copilot_reply: str,
        file_name: Optional[str] = None
    ) -> str:
        """
        å„²å­˜ Copilot å°è©±åˆ°å…±ç”¨è¨˜æ†¶è³‡æ–™åº«
        
        åƒæ•¸:
            conversation_id: å°è©± ID
            user_id: ç”¨æˆ¶ ID
            session_id: Session ID
            user_prompt: ç”¨æˆ¶æç¤º
            copilot_reply: Copilot å›è¦†
            file_name: æª”æ¡ˆåç¨±
        
        è¿”å›:
            è¨˜æ†¶ ID
        """
        try:
            memory_data = {
                "conversation_id": conversation_id,
                "user_id": user_id,
                "user_message": user_prompt,
                "assistant_message": copilot_reply,
                "file_name": file_name,
                "memory_type": config.COPILOT_MEMORY_TYPE,
                "platform": config.COPILOT_PLATFORM,
                "ai_id": config.COPILOT_AI_ID,
                "session_id": session_id,
                "source": "copilot_agent",
                "created_at": datetime.utcnow().isoformat(),
                "importance_score": 0.7,
                "access_count": 0
            }
            
            response = self.supabase.table(config.SUPABASE_MEMORIES_TABLE).insert(
                memory_data
            ).execute()
            
            if response.data:
                memory_id = response.data[0].get("id")
                logger.info(f"ğŸ’¾ è¨˜æ†¶å·²å„²å­˜ | ID: {memory_id}")
                return str(memory_id)
            
            return ""
            
        except Exception as e:
            logger.error(f"âŒ å„²å­˜è¨˜æ†¶å¤±æ•—: {e}")
            raise
    
    async def generate_and_save_reflection(
        self,
        conversation_id: str,
        user_id: str,
        session_id: str,
        user_prompt: str,
        copilot_reply: str,
        memory_id: Optional[str] = None
    ) -> Dict:
        """
        ç”Ÿæˆåæ€æ‘˜è¦ä¸¦å„²å­˜åˆ°å…±ç”¨è³‡æ–™åº«
        
        åƒæ•¸:
            conversation_id: å°è©± ID
            user_id: ç”¨æˆ¶ ID
            session_id: Session ID
            user_prompt: ç”¨æˆ¶æç¤º
            copilot_reply: Copilot å›è¦†
            memory_id: å°æ‡‰çš„è¨˜æ†¶ ID
        
        è¿”å›:
            åæ€è³‡æ–™
        """
        try:
            # ç”Ÿæˆåæ€å…§å®¹
            reflection_prompt = f"""
åˆ†æä»¥ä¸‹å°è©±ï¼Œç”Ÿæˆç°¡æ½”çš„åæ€æ‘˜è¦ï¼š

ç”¨æˆ¶å•é¡Œ: {user_prompt}
åŠ©æ‰‹å›è¦†: {copilot_reply}

è«‹æä¾›ï¼š
1. é€™æ¬¡å°è©±çš„é—œéµæ´å¯Ÿ
2. å¯æ”¹é€²çš„åœ°æ–¹
3. ç›¸é—œæŠ€è¡“æ¨™ç±¤

ä»¥ JSON æ ¼å¼å›è¦†ï¼š
{{
  "insight": "é—œéµæ´å¯Ÿ",
  "improvement": "æ”¹é€²å»ºè­°",
  "tags": ["tag1", "tag2"]
}}
"""
            
            response = self.openai_client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„åæ€åˆ†æå¸«ã€‚"},
                    {"role": "user", "content": reflection_prompt}
                ],
                max_tokens=200,
                temperature=0.5
            )
            
            reflection_text = response.choices[0].message.content
            
            # å˜—è©¦è§£æ JSON
            try:
                reflection_data = json.loads(reflection_text)
            except:
                reflection_data = {
                    "insight": reflection_text,
                    "improvement": "",
                    "tags": []
                }
            
            # å„²å­˜åˆ°è³‡æ–™åº«
            reflection_record = {
                "conversation_id": conversation_id,
                "user_id": user_id,
                "reflection_content": reflection_data.get("insight", ""),
                "confidence_score": 0.8,
                "analysis_tags": json.dumps(reflection_data.get("tags", [])),
                "copilot_snapshot_id": session_id,
                "related_message_id": memory_id,
                "created_at": datetime.utcnow().isoformat()
            }
            
            supabase_response = self.supabase.table(
                config.SUPABASE_REFLECTIONS_TABLE
            ).insert(reflection_record).execute()
            
            logger.info(f"ğŸ’­ åæ€å·²å„²å­˜")
            
            return {
                "content": reflection_data.get("insight", ""),
                "confidence": 0.8,
                "tags": reflection_data.get("tags", [])
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆåæ€å¤±æ•—: {e}")
            return {
                "content": "åæ€ç”Ÿæˆå¤±æ•—",
                "confidence": 0.0,
                "tags": []
            }
    
    async def save_session_status(
        self,
        session_id: str,
        status: str,
        file_name: Optional[str] = None
    ):
        """
        å„²å­˜ session ç‹€æ…‹åˆ° Redis
        
        åƒæ•¸:
            session_id: Session ID
            status: ç‹€æ…‹ï¼ˆprocessing/completed/failedï¼‰
            file_name: æª”æ¡ˆåç¨±
        """
        try:
            redis_key = f"copilot:session:{session_id}"
            session_data = {
                "status": status,
                "file_name": file_name,
                "created_at": datetime.utcnow().isoformat()
            }
            
            self.redis.redis.setex(
                redis_key,
                config.SESSION_TTL,
                json.dumps(session_data, ensure_ascii=False)
            )
            
            logger.info(f"ğŸ“Š Session ç‹€æ…‹å·²å„²å­˜: {session_id} -> {status}")
            
        except Exception as e:
            logger.error(f"âŒ å„²å­˜ session ç‹€æ…‹å¤±æ•—: {e}")
    
    async def get_session_status(self, session_id: str) -> Optional[Dict]:
        """
        å¾ Redis å–å¾— session ç‹€æ…‹
        
        åƒæ•¸:
            session_id: Session ID
        
        è¿”å›:
            Session è³‡æ–™
        """
        try:
            redis_key = f"copilot:session:{session_id}"
            data = self.redis.redis.get(redis_key)
            
            if data:
                if isinstance(data, bytes):
                    data = data.decode('utf-8')
                return json.loads(data)
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ å–å¾— session ç‹€æ…‹å¤±æ•—: {e}")
            return None
