from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from backend.supabase_handler import get_supabase
from backend.modules.memory.redis_interface import RedisInterface
from backend.modules.ipfs_handler import get_ipfs_handler
import logging
import json
from datetime import datetime
from typing import Optional, List, Dict, Any
import os

router = APIRouter()
logger = logging.getLogger("archive_conversation")

supabase = get_supabase()
redis_interface = RedisInterface()
ipfs_handler = get_ipfs_handler()

class ArchiveRequest(BaseModel):
    conversation_id: str
    user_id: str = "default_user"
    include_attachments: bool = True

class ArchiveResponse(BaseModel):
    success: bool
    ipfs_cid: Optional[str] = None
    gateway_url: Optional[str] = None
    archive_id: Optional[str] = None
    message: str
    archived_at: str

async def get_conversation_from_redis(conversation_id: str) -> List[Dict]:
    """å¾ Redis ç²å–å°è©±è¨˜éŒ„"""
    try:
        redis_key = f"conversations:{conversation_id}"
        conversations = []
        
        raw_data = redis_interface.redis.lrange(redis_key, 0, -1)
        
        for item in raw_data:
            if isinstance(item, bytes):
                item = item.decode('utf-8')
            try:
                conversations.append(json.loads(item))
            except:
                pass
        
        logger.info(f"ğŸ“¥ å¾ Redis è®€å– {len(conversations)} æ¢å°è©±è¨˜éŒ„")
        return conversations
        
    except Exception as e:
        logger.warning(f"âš ï¸ Redis è®€å–å¤±æ•—: {e}")
        return []

async def get_conversation_from_supabase(conversation_id: str) -> List[Dict]:
    """å¾ Supabase ç²å–å°è©±è¨˜éŒ„"""
    try:
        memories_table = os.getenv("SUPABASE_MEMORIES_TABLE", "xiaochenguang_memories")
        
        response = supabase.table(memories_table).select("*").eq(
            "conversation_id", conversation_id
        ).order("created_at", desc=False).execute()
        
        if response.data:
            logger.info(f"ğŸ“¥ å¾ Supabase è®€å– {len(response.data)} æ¢å°è©±è¨˜éŒ„")
            return response.data
        return []
        
    except Exception as e:
        logger.error(f"âŒ Supabase è®€å–å¤±æ•—: {e}")
        return []

async def get_uploaded_files(conversation_id: str) -> List[Dict]:
    """ç²å–å°è©±ä¸­ä¸Šå‚³çš„æª”æ¡ˆæ‘˜è¦"""
    try:
        pattern = f"upload:{conversation_id}:*"
        file_keys = []
        
        try:
            cursor = '0'
            while cursor != 0:
                cursor, keys = redis_interface.redis.scan(cursor, match=pattern, count=100)
                file_keys.extend(keys)
                if cursor == 0 or cursor == '0':
                    break
        except:
            file_keys = []
        
        files = []
        for key in file_keys:
            try:
                if isinstance(key, bytes):
                    key = key.decode('utf-8')
                file_data = redis_interface.redis.get(key)
                if file_data:
                    if isinstance(file_data, bytes):
                        file_data = file_data.decode('utf-8')
                    files.append(json.loads(file_data))
            except Exception as e:
                logger.warning(f"âš ï¸ è®€å–æª”æ¡ˆè³‡æ–™å¤±æ•—: {e}")
        
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(files)} å€‹ä¸Šå‚³æª”æ¡ˆ")
        return files
        
    except Exception as e:
        logger.error(f"âŒ ç²å–æª”æ¡ˆåˆ—è¡¨å¤±æ•—: {e}")
        return []

@router.post("/archive_conversation", response_model=ArchiveResponse)
async def archive_conversation(request: ArchiveRequest):
    """
    å°è©±å°å­˜ç«¯é»
    å°‡å®Œæ•´å°è©±æ‰“åŒ…ä¸¦ä¸Šå‚³åˆ° IPFSï¼ŒåŒæ™‚å„²å­˜ CID åˆ° Supabase
    """
    try:
        logger.info(f"ğŸ—‚ï¸ é–‹å§‹å°å­˜å°è©±: {request.conversation_id}")
        
        redis_conversations = await get_conversation_from_redis(request.conversation_id)
        supabase_conversations = await get_conversation_from_supabase(request.conversation_id)
        
        all_conversations = supabase_conversations if supabase_conversations else redis_conversations
        
        logger.info(f"ğŸ“Š æ•¸æ“šä¾†æº - Redis: {len(redis_conversations)} æ¢, Supabase: {len(supabase_conversations)} æ¢")
        logger.info(f"ğŸ“¦ ä½¿ç”¨ {'Supabase (å®Œæ•´)' if supabase_conversations else 'Redis (å¿«å–)'} æ•¸æ“šé€²è¡Œå°å­˜")
        
        if not all_conversations:
            raise HTTPException(
                status_code=404,
                detail="æ‰¾ä¸åˆ°å°è©±è¨˜éŒ„"
            )
        
        uploaded_files = []
        if request.include_attachments:
            uploaded_files = await get_uploaded_files(request.conversation_id)
        
        messages = []
        for conv in all_conversations:
            if isinstance(conv, dict):
                messages.append({
                    "role": "user",
                    "content": conv.get("user_message", ""),
                    "timestamp": conv.get("created_at", conv.get("timestamp", ""))
                })
                messages.append({
                    "role": "assistant",
                    "content": conv.get("assistant_message", ""),
                    "timestamp": conv.get("created_at", conv.get("timestamp", ""))
                })
        
        archive_data = {
            "conversation_id": request.conversation_id,
            "user_id": request.user_id,
            "ai_id": os.getenv("AI_ID", "xiaochenguang_v1"),
            "archived_at": datetime.utcnow().isoformat(),
            "message_count": len(messages),
            "messages": messages,
            "attachments": [
                {
                    "file_name": f.get("file_name"),
                    "file_type": f.get("file_type"),
                    "summary": f.get("summary"),
                    "uploaded_at": f.get("uploaded_at")
                }
                for f in uploaded_files
            ],
            "metadata": {
                "total_messages": len(messages),
                "total_attachments": len(uploaded_files),
                "archive_version": "1.0"
            }
        }
        
        logger.info(f"ğŸ“¦ æº–å‚™ä¸Šå‚³å°å­˜: {len(messages)} æ¢è¨Šæ¯, {len(uploaded_files)} å€‹é™„ä»¶")
        
        ipfs_result = await ipfs_handler.upload_to_ipfs(
            archive_data,
            name=f"conversation_{request.conversation_id}"
        )
        
        ipfs_cid = ipfs_result.get("cid") or ipfs_result.get("ipfs_hash") or ipfs_result.get("local_cid")
        
        if not ipfs_cid:
            raise HTTPException(
                status_code=500,
                detail=f"ç„¡æ³•ç”Ÿæˆ CID: {ipfs_result.get('error', 'Unknown error')}"
            )
        
        uploaded_to_pinata = ipfs_result.get("success", False)
        gateway_url = ipfs_result.get("gateway_url", f"https://gateway.pinata.cloud/ipfs/{ipfs_cid}")
        
        if uploaded_to_pinata:
            logger.info(f"âœ… å°è©±å·²ä¸Šå‚³åˆ° Pinata IPFS: {ipfs_cid}")
        else:
            logger.warning(f"âš ï¸ Pinata ä¸Šå‚³å¤±æ•—ï¼Œä½¿ç”¨æœ¬åœ° CID: {ipfs_cid}")
            gateway_url = f"ipfs://{ipfs_cid}"
        
        try:
            archive_table = os.getenv("SUPABASE_ARCHIVE_TABLE", "conversation_archive")
            archive_record = {
                "conversation_id": request.conversation_id,
                "user_id": request.user_id,
                "ipfs_cid": ipfs_cid,
                "gateway_url": gateway_url,
                "message_count": len(messages),
                "attachment_count": len(uploaded_files),
                "created_at": datetime.utcnow().isoformat()
            }
            
            db_response = supabase.table(archive_table).insert(archive_record).execute()
            
            archive_id = None
            if db_response.data and len(db_response.data) > 0:
                archive_id = db_response.data[0].get("id")
                logger.info(f"âœ… å°å­˜è¨˜éŒ„å·²å„²å­˜åˆ° Supabase: {archive_id}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Supabase å„²å­˜å¤±æ•—ï¼ˆä¸å½±éŸ¿ IPFS ä¸Šå‚³ï¼‰: {e}")
            archive_id = None
        
        return ArchiveResponse(
            success=True,
            ipfs_cid=ipfs_cid,
            gateway_url=gateway_url,
            archive_id=archive_id,
            message=f"å°è©±å·²æˆåŠŸå°å­˜åˆ° IPFSï¼ˆ{len(messages)} æ¢è¨Šæ¯ï¼‰",
            archived_at=datetime.utcnow().isoformat()
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å°è©±å°å­˜å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å°å­˜å¤±æ•—: {str(e)}")
