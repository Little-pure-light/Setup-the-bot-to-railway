# è¨˜æ†¶æ¨¡çµ„ï¼ˆMemory Moduleï¼‰

> AI æ•¸å­—å®‡å®™çš„ä¸­æ¨ç¥ç¶“è³‡æ–™å±¤

## ğŸ“˜ æ¨¡çµ„ç”¨é€”

è¨˜æ†¶æ¨¡çµ„æ˜¯å°å®¸å…‰ AI ç³»çµ±çš„æ ¸å¿ƒæ•¸æ“šå±¤ï¼Œè² è²¬ï¼š

1. **å°è©±ç´€éŒ„æ•¸å­—åŒ–**ï¼šä½¿ç”¨ Token åŒ–æŠ€è¡“å°‡æ‰€æœ‰æ–‡å­—è½‰æ›ç‚ºæ•¸å­—åºåˆ—
2. **é›™å±¤è¨˜æ†¶æ¶æ§‹**ï¼š
   - **çŸ­æœŸè¨˜æ†¶**ï¼šRedis å¿«å–ï¼ˆ2å¤© TTLï¼‰
   - **é•·æœŸè¨˜æ†¶**ï¼šSupabase æ°¸ä¹…å„²å­˜
3. **åæ€ç´€éŒ„ç´¢å¼•**ï¼šå„²å­˜ AI çš„è‡ªæˆ‘åæ€çµæœ
4. **IPFS æ•´åˆ**ï¼šï¼ˆé ç•™ï¼‰æœªä¾†æ”¯æ´å»ä¸­å¿ƒåŒ–å„²å­˜
5. **çµ±ä¸€è³‡æ–™ä»‹é¢**ï¼šä¾›æ‰€æœ‰æ¨¡çµ„èª¿ç”¨çš„æ¨™æº– API

## ğŸ—ï¸ æ¶æ§‹è¨­è¨ˆ

```
Memory Module
â”œâ”€â”€ tokenizer.py          # Token åŒ–å¼•æ“ï¼ˆtiktoken + é™ç´šæ–¹æ¡ˆï¼‰
â”œâ”€â”€ io_contract.py        # I/O åˆç´„å±¤ï¼ˆè³‡æ–™æ ¡é©—èˆ‡æ¨™æº–åŒ–ï¼‰
â”œâ”€â”€ redis_interface.py    # Redis çŸ­æœŸè¨˜æ†¶æ¥å£
â”œâ”€â”€ supabase_interface.py # Supabase é•·æœŸè¨˜æ†¶æ¥å£
â”œâ”€â”€ core.py              # è¨˜æ†¶æ ¸å¿ƒæ§åˆ¶å™¨
â””â”€â”€ config.json          # æ¨¡çµ„é…ç½®
```

## ğŸ”§ ç’°å¢ƒè®Šæ•¸

### å¿…è¦è®Šæ•¸

```bash
# Supabase é…ç½®ï¼ˆå·²åœ¨å°ˆæ¡ˆä¸­è¨­å®šï¼‰
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_key

# Redis é…ç½®ï¼ˆå¯é¸ï¼Œæœªè¨­å®šå‰‡ä½¿ç”¨ Mockï¼‰
REDIS_URL=redis://:password@host:6379/0
```

### å¯é¸è®Šæ•¸

```bash
# Token åŒ–é…ç½®
TOKENIZER_NAME=cl100k_base

# Redis TTL è¨­å®šï¼ˆç§’ï¼‰
MEMORY_REDIS_TTL_SECONDS=172800  # é è¨­ 2 å¤©

# æ‰¹æ¬¡åˆ·å¯«å¤§å°
MEMORY_FLUSH_BATCH_SIZE=100

# è³‡æ–™è¡¨æ˜ å°„ï¼ˆJSON æ ¼å¼ï¼‰
MEMORY_TABLE_MAP='{"conversations":"xiaochenguang_memories","reflections":"xiaochenguang_reflections"}'
```

## ğŸ“Š è³‡æ–™è¡¨çµæ§‹

### xiaochenguang_memoriesï¼ˆå°è©±è¨˜æ†¶è¡¨ï¼‰

| æ¬„ä½ | é¡å‹ | èªªæ˜ |
|------|------|------|
| id | uuid | ä¸»éµ |
| conversation_id | text | å°è©± ID |
| user_id | text | ä½¿ç”¨è€… ID |
| user_message | text | ä½¿ç”¨è€…è¨Šæ¯ï¼ˆå¯é¸ï¼‰ |
| assistant_message | text | AI å›è¦†ï¼ˆå¯é¸ï¼‰ |
| reflection | jsonb | åæ€çµæœ |
| token_data | jsonb | **Token è³‡æ–™ï¼ˆæ ¸å¿ƒï¼‰** |
| cid | text | IPFS ç´¢å¼•ï¼ˆé¸ç”¨ï¼‰ |
| created_at | timestamptz | å»ºç«‹æ™‚é–“ |
| importance_score | float | é‡è¦æ€§è©•åˆ† |
| access_count | int | å­˜å–æ¬¡æ•¸ |

### token_data çµæ§‹

```json
{
  "user": [1234, 5678, 9012],
  "assistant": [3456, 7890, 1234],
  "reflection": [5678, 9012],
  "method": "tiktoken",
  "encoding": "cl100k_base",
  "total_count": 9,
  "timestamp": "2025-10-19T12:00:00"
}
```

## ğŸ”Œ æ¬„ä½æ˜ å°„é…ç½®

å¦‚æœç¾æœ‰è³‡æ–™è¡¨æ¬„ä½åç¨±ä¸åŒï¼Œå¯åœ¨ `config.json` ä¸­è¨­å®šæ˜ å°„ï¼š

```json
{
  "columns_map": {
    "conversation_id": "conv_id",
    "user_message": "user_msg",
    "assistant_message": "ai_response"
  }
}
```

## ğŸ’» ä½¿ç”¨æ–¹å¼

### 1. åŸºæœ¬ä½¿ç”¨

```python
from backend.modules.memory.core import MemoryCore

# åˆå§‹åŒ–
memory = MemoryCore()

# å„²å­˜å°è©±
result = memory.save_chat(
    user_message="ä½ å¥½ï¼Œå°å®¸å…‰ï¼",
    assistant_message="ä½ å¥½ï¼å¾ˆé«˜èˆˆè¦‹åˆ°ä½ ï¼",
    conversation_id="conv_001",
    user_id="user_123"
)

# è®€å–ä¸Šä¸‹æ–‡
context = memory.load_recent_context("conv_001")
```

### 2. æ•´åˆåˆ°èŠå¤©è·¯ç”±

åœ¨ `chat_router.py` ä¸­æ·»åŠ ï¼ˆä¸æ”¹è®Š APIï¼‰ï¼š

```python
from backend.modules.memory.core import MemoryCore

memory_core = MemoryCore()

# åœ¨ç”Ÿæˆå›è¦†å¾Œ
memory_core.store_conversation(
    conversation_id=request.conversation_id,
    user_id=request.user_id,
    user_msg=user_message,
    assistant_msg=assistant_message,
    reflection=reflection_obj
)
```

### 3. å„²å­˜åæ€

```python
result = memory.save_reflection(
    reflection_text={
        "summary": "å›æ‡‰éæ–¼ç°¡çŸ­",
        "causes": ["ç¼ºå°‘å¯¦ä¾‹", "æœªæ·±å…¥è§£é‡‹"],
        "improvements": ["å¢åŠ ç¯„ä¾‹", "æä¾›æ›´å¤šç´°ç¯€"]
    },
    conversation_id="conv_001",
    user_id="user_123"
)
```

## ğŸ§ª æœ¬åœ°æ¸¬è©¦æ­¥é©Ÿ

### 1. Token åŒ–æ¸¬è©¦

```python
from backend.modules.memory.tokenizer import TokenizerEngine

tokenizer = TokenizerEngine()
tokens = tokenizer.tokenize_text("æ¸¬è©¦æ–‡å­—")
print(f"Token æ•¸é‡: {len(tokens)}")
```

### 2. Redis å¿«å–æ¸¬è©¦

```python
from backend.modules.memory.redis_interface import RedisInterface

redis = RedisInterface()
redis.store_short_term("test_conv", {"test": "data"})
data = redis.load_recent_context("test_conv")
```

### 3. Supabase å„²å­˜æ¸¬è©¦

```python
from backend.modules.memory.supabase_interface import SupabaseInterface

supabase = SupabaseInterface()
result = supabase.store_single_memory({
    "conversation_id": "test_001",
    "user_id": "user_123",
    "token_data": {"user": [1,2,3]},
    "created_at": "2025-10-19T12:00:00"
})
```

### 4. å®Œæ•´æµç¨‹æ¸¬è©¦

```python
from backend.modules.memory.core import MemoryCore

memory = MemoryCore()

# å„²å­˜å°è©±
result = memory.save_chat(
    user_message="æ¸¬è©¦",
    assistant_message="æ”¶åˆ°",
    conversation_id="test_conv",
    user_id="test_user"
)

print(f"Redis: {result['redis_stored']}")
print(f"Supabase: {result['supabase_stored']}")
print(f"Token æ•¸: {result['token_count']}")
```

## ğŸ”„ æ‰¹æ¬¡åˆ·å¯«æ©Ÿåˆ¶

è¨˜æ†¶æ¨¡çµ„æ”¯æ´è‡ªå‹•æ‰¹æ¬¡åˆ·å¯«ï¼š

### å•Ÿå‹•åˆ·å¯«å·¥ä½œå™¨

```python
from backend.jobs.memory_flush_worker import create_flush_worker
from backend.modules.memory.core import MemoryCore

memory = MemoryCore()
worker = create_flush_worker(memory, interval_seconds=300)

# å•Ÿå‹•
await worker.start()
```

### æ‰‹å‹•è§¸ç™¼åˆ·å¯«

```python
result = await worker.manual_flush()
print(f"åˆ·å¯« {result['flushed_count']} ç­†è¨˜éŒ„")
```

## ğŸ›¡ï¸ å®‰å…¨æ€§

1. **è³‡æ–™åŠ å¯†**ï¼štext_cache æ¬„ä½å¯è¨­å®šåŠ å¯†ï¼ˆAESï¼‰
2. **IPFS ç°½å**ï¼šä¸Šå‚³å‰å…ˆåš SHA256 é›œæ¹Š
3. **å­˜å–æ§åˆ¶**ï¼šæ‰€æœ‰æ“ä½œéœ€é€šé user_id é©—è­‰

## âš™ï¸ å•Ÿç”¨/åœç”¨æ¨¡çµ„

ç·¨è¼¯ `config.json`ï¼š

```json
{
  "enabled": true  // æ”¹ç‚º false åœç”¨
}
```

é‡å•Ÿ Backend workflow å³å¯ã€‚

## ğŸ“ˆ æ•ˆèƒ½å„ªåŒ–

- **Redis éåŒæ­¥**ï¼šé¿å…é˜»å¡ä¸»ç·šç¨‹
- **æ‰¹æ¬¡å¯«å…¥**ï¼šæ¸›å°‘ Supabase è«‹æ±‚æ¬¡æ•¸
- **Token å£“ç¸®**ï¼šä½¿ç”¨ jsonb æ¬„ä½å„²å­˜

## âŒ å¸¸è¦‹éŒ¯èª¤èˆ‡æ’é™¤

### 1. tiktoken ç„¡æ³•å®‰è£

**ç—‡ç‹€**ï¼š`ImportError: No module named 'tiktoken'`

**è§£æ±º**ï¼šæ¨¡çµ„æœƒè‡ªå‹•åˆ‡æ›åˆ° UTF-8 bytes é™ç´šæ–¹æ¡ˆ

### 2. Redis é€£æ¥å¤±æ•—

**ç—‡ç‹€**ï¼š`Redis connection refused`

**è§£æ±º**ï¼šæª¢æŸ¥ `REDIS_URL` æˆ–ä½¿ç”¨å…§å»º Mock

### 3. Supabase å¯«å…¥å¤±æ•—

**ç—‡ç‹€**ï¼š`Supabase error: column not found`

**è§£æ±º**ï¼šæª¢æŸ¥ `columns_map` è¨­å®šæ˜¯å¦æ­£ç¢º

### 4. Token æ•¸é‡ç•°å¸¸

**ç—‡ç‹€**ï¼šToken æ•¸é‡ç‚º 0 æˆ–éå¤§

**è§£æ±º**ï¼š
```python
# æª¢æŸ¥ tokenizer ç‹€æ…‹
print(tokenizer.fallback_mode)
print(tokenizer.tokenizer_name)
```

## ğŸ”— æ¨¡çµ„é€šä¿¡

å…¶ä»–æ¨¡çµ„èª¿ç”¨è¨˜æ†¶æ¨¡çµ„çš„æ¨™æº–æ–¹å¼ï¼š

```python
from backend.core_controller import get_core_controller

controller = await get_core_controller()
memory_module = await controller.get_module("memory")

# å‘¼å«åŠŸèƒ½
result = await memory_module.process({
    "operation": "save_chat",
    "user_message": "...",
    "assistant_message": "...",
    "conversation_id": "...",
    "user_id": "..."
})
```

## ğŸ“š ç›¸é—œæ–‡æª”

- [åæ€æ¨¡çµ„æ–‡æª”](../../reflection_module/README.md)
- [æ ¸å¿ƒæ§åˆ¶å™¨æ–‡æª”](../../core_controller.py)
- [è³‡æ–™åº«è¨­å®šæŒ‡å—](../../../others/DATABASE_SETUP.md)

---

**ç‰ˆæœ¬**ï¼š2.0.0  
**æœ€å¾Œæ›´æ–°**ï¼š2025-10-19  
**ç‹€æ…‹**ï¼šâœ… å·²å•Ÿç”¨
