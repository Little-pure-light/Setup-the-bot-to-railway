"""
Pinecone å‘é‡è³‡æ–™åº«è™•ç†å™¨ - Pinecone Vector Database Handler
è² è²¬å°‡åæ€çš„äººæ ¼å‘é‡å„²å­˜åˆ° Pinecone ä»¥ä¾¿å¾ŒçºŒæª¢ç´¢
ä½¿ç”¨ Pinecone å…§å»ºçš„ llama-text-embed-v2 æ¨¡å‹ç”Ÿæˆå‘é‡
"""
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
import json


class PineconeHandler:
    """Pinecone å‘é‡è³‡æ–™åº«æ¥å£é¡"""

    def __init__(self):
        """åˆå§‹åŒ– Pinecone é€£æ¥"""
        self.api_key = os.getenv("PINECONE_API_KEY")
        self.environment = os.getenv("PINECONE_ENVIRONMENT")
        self.index_name = os.getenv("PINECONE_INDEX_NAME")
        
        self.pc = None
        self.index = None
        self.embed_model = None
        self.initialized = False
        
        if self.api_key and self.index_name:
            self._initialize_pinecone()
        else:
            print("âš ï¸ Pinecone ç’°å¢ƒè®Šæ•¸æœªè¨­å®šï¼Œå‘é‡å„²å­˜åŠŸèƒ½å°‡è¢«ç¦ç”¨")

    def _initialize_pinecone(self):
        """åˆå§‹åŒ– Pinecone å®¢æˆ¶ç«¯å’Œç´¢å¼•ï¼ˆä¸é å…ˆè¼‰å…¥ embedding æ¨¡å‹ï¼‰"""
        try:
            from pinecone import Pinecone, ServerlessSpec
            
            self.pc = Pinecone(api_key=self.api_key)
            print(f"âœ… Pinecone å®¢æˆ¶ç«¯å·²åˆå§‹åŒ–")
            
            existing_indexes = [index.name for index in self.pc.list_indexes()]
            
            if self.index_name not in existing_indexes:
                print(f"ğŸ”§ å»ºç«‹æ–°çš„ Pinecone ç´¢å¼•: {self.index_name}")
                self.pc.create_index(
                    name=self.index_name,
                    dimension=4096,
                    metric='cosine',
                    spec=ServerlessSpec(
                        cloud='aws',
                        region=self.environment or 'us-east-1'
                    )
                )
                print(f"âœ… Pinecone ç´¢å¼•å·²å»ºç«‹ (dimension=4096, metric=cosine)")
            else:
                print(f"âœ… Pinecone ç´¢å¼•å·²å­˜åœ¨: {self.index_name}")
            
            self.index = self.pc.Index(self.index_name)
            self.initialized = True
            print(f"âœ… Pinecone å‘é‡è³‡æ–™åº«å·²å°±ç·’ (ä½¿ç”¨ llama-text-embed-v2 æ¨¡å‹)")
            
        except Exception as e:
            print(f"âŒ Pinecone åˆå§‹åŒ–å¤±æ•—: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            self.initialized = False

    def generate_embedding(self, text: str) -> Optional[List[float]]:
        """
        ä½¿ç”¨ Pinecone çš„ llama-text-embed-v2 ç”Ÿæˆæ–‡æœ¬å‘é‡
        
        åƒæ•¸:
            text: è¦ç”Ÿæˆå‘é‡çš„æ–‡æœ¬
        
        è¿”å›:
            å‘é‡åˆ—è¡¨æˆ– None
        """
        if not self.initialized:
            print("âš ï¸ Pinecone æœªåˆå§‹åŒ–ï¼Œç„¡æ³•ç”Ÿæˆå‘é‡")
            return None
        
        try:
            response = self.pc.inference.embed(
                model="llama-text-embed-v2",
                inputs=[text],
                parameters={"input_type": "passage"}
            )
            
            if response and len(response.data) > 0:
                embedding = response.data[0].values
                print(f"âœ… ç”Ÿæˆå‘é‡æˆåŠŸ (ç¶­åº¦: {len(embedding)})")
                return embedding
            else:
                print("âš ï¸ Pinecone è¿”å›ç©ºå‘é‡")
                return None
                
        except Exception as e:
            print(f"âŒ Pinecone ç”Ÿæˆå‘é‡å¤±æ•—: {type(e).__name__}: {e}")
            return None

    def store_reflection_vector(
        self,
        reflection_id: str,
        embedding: List[float],
        metadata: Dict[str, Any]
    ) -> bool:
        """
        å„²å­˜åæ€å‘é‡åˆ° Pinecone
        
        åƒæ•¸:
            reflection_id: åæ€è¨˜éŒ„çš„å”¯ä¸€ ID
            embedding: 4096 ç¶­çš„å‘é‡ï¼ˆå¾ Pinecone llama-text-embed-v2 ç”Ÿæˆï¼‰
            metadata: å…ƒæ•¸æ“šï¼ˆåŒ…å«æ‘˜è¦ã€æ¨™ç±¤ã€æ™‚é–“ç­‰ï¼‰
        
        è¿”å›:
            æ˜¯å¦æˆåŠŸ
        """
        if not self.initialized:
            print("âš ï¸ Pinecone æœªåˆå§‹åŒ–ï¼Œè·³éå‘é‡å„²å­˜")
            return False
        
        try:
            safe_metadata = self._sanitize_metadata(metadata)
            
            self.index.upsert(
                vectors=[{
                    "id": reflection_id,
                    "values": embedding,
                    "metadata": safe_metadata
                }]
            )
            
            print(f"âœ… åæ€å‘é‡å·²å„²å­˜åˆ° Pinecone: {reflection_id}")
            return True
            
        except Exception as e:
            print(f"âŒ Pinecone å‘é‡å„²å­˜å¤±æ•—: {type(e).__name__}: {e}")
            return False
    
    def store_reflection_with_text(
        self,
        reflection_id: str,
        reflection_text: str,
        metadata: Dict[str, Any]
    ) -> bool:
        """
        å¾æ–‡æœ¬è‡ªå‹•ç”Ÿæˆå‘é‡ä¸¦å„²å­˜åˆ° Pinecone
        
        åƒæ•¸:
            reflection_id: åæ€è¨˜éŒ„çš„å”¯ä¸€ ID
            reflection_text: åæ€æ‘˜è¦æ–‡æœ¬ï¼ˆç”¨æ–¼ç”Ÿæˆå‘é‡ï¼‰
            metadata: å…ƒæ•¸æ“š
        
        è¿”å›:
            æ˜¯å¦æˆåŠŸ
        """
        embedding = self.generate_embedding(reflection_text)
        
        if embedding is None:
            print("âš ï¸ å‘é‡ç”Ÿæˆå¤±æ•—ï¼Œè·³éå„²å­˜")
            return False
        
        return self.store_reflection_vector(reflection_id, embedding, metadata)

    def query_similar_reflections(
        self,
        query_embedding: List[float],
        top_k: int = 5,
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥è©¢ç›¸ä¼¼çš„åæ€å‘é‡
        
        åƒæ•¸:
            query_embedding: æŸ¥è©¢å‘é‡
            top_k: è¿”å›å‰ K å€‹æœ€ç›¸ä¼¼çµæœ
            filter_metadata: å…ƒæ•¸æ“šéæ¿¾æ¢ä»¶ï¼ˆå¯é¸ï¼‰
        
        è¿”å›:
            ç›¸ä¼¼åæ€åˆ—è¡¨
        """
        if not self.initialized:
            print("âš ï¸ Pinecone æœªåˆå§‹åŒ–ï¼Œç„¡æ³•æŸ¥è©¢")
            return []
        
        try:
            query_params = {
                "vector": query_embedding,
                "top_k": top_k,
                "include_metadata": True
            }
            
            if filter_metadata:
                query_params["filter"] = filter_metadata
            
            results = self.index.query(**query_params)
            
            similar_reflections = []
            for match in results.get("matches", []):
                similar_reflections.append({
                    "id": match.get("id"),
                    "score": match.get("score"),
                    "metadata": match.get("metadata", {})
                })
            
            print(f"ğŸ” æ‰¾åˆ° {len(similar_reflections)} å€‹ç›¸ä¼¼åæ€")
            return similar_reflections
            
        except Exception as e:
            print(f"âŒ Pinecone æŸ¥è©¢å¤±æ•—: {type(e).__name__}: {e}")
            return []

    def delete_reflection(self, reflection_id: str) -> bool:
        """
        åˆªé™¤æŒ‡å®šçš„åæ€å‘é‡
        
        åƒæ•¸:
            reflection_id: åæ€è¨˜éŒ„ ID
        
        è¿”å›:
            æ˜¯å¦æˆåŠŸ
        """
        if not self.initialized:
            return False
        
        try:
            self.index.delete(ids=[reflection_id])
            print(f"âœ… å·²å¾ Pinecone åˆªé™¤åæ€: {reflection_id}")
            return True
        except Exception as e:
            print(f"âŒ Pinecone åˆªé™¤å¤±æ•—: {e}")
            return False

    def _sanitize_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¸…ç†å…ƒæ•¸æ“šï¼ˆPinecone é™åˆ¶ï¼šå€¼å¿…é ˆæ˜¯å­—ä¸²ã€æ•¸å­—ã€å¸ƒæ—æˆ–åˆ—è¡¨ï¼‰
        """
        sanitized = {}
        
        for key, value in metadata.items():
            if isinstance(value, (str, int, float, bool)):
                sanitized[key] = value
            elif isinstance(value, (dict, list)):
                sanitized[key] = json.dumps(value, ensure_ascii=False)
            elif value is None:
                sanitized[key] = ""
            else:
                sanitized[key] = str(value)
        
        return sanitized

    def get_stats(self) -> Dict[str, Any]:
        """
        ç²å– Pinecone çµ±è¨ˆè³‡è¨Š
        
        è¿”å›:
            çµ±è¨ˆè³‡è¨Š
        """
        if not self.initialized:
            return {
                "status": "disabled",
                "reason": "Pinecone ç’°å¢ƒè®Šæ•¸æœªè¨­å®š"
            }
        
        try:
            stats = self.index.describe_index_stats()
            return {
                "status": "active",
                "index_name": self.index_name,
                "total_vectors": stats.get("total_vector_count", 0),
                "dimension": stats.get("dimension", 1536)
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
