"""
åæ€æ¨¡çµ„ - Reflection Module
å¯¦ç¾ã€Œåæ¨æœå› æ³•å‰‡ã€(Causal Retrospection)çš„è‡ªæˆ‘èªçŸ¥ç³»çµ±

æ ¸å¿ƒç†å¿µï¼š
ä¸æ˜¯å•ã€Œç‚ºä»€éº¼æˆ‘é€™æ¨£å›ç­”ã€ï¼Œè€Œæ˜¯å•ã€Œä»€éº¼åŸå› å°è‡´æˆ‘å¿…é ˆé€™æ¨£å›ç­”ã€
é€™æ˜¯å¾æœæº¯å› çš„æ·±å±¤æ€è€ƒæ¨¡å¼ï¼Œæ¨¡æ“¬äººé¡çš„å…ƒèªçŸ¥èƒ½åŠ›

è¨­è¨ˆå“²å­¸ï¼š
- æ¯å€‹å›ç­”ï¼ˆæœï¼‰èƒŒå¾Œéƒ½æœ‰æ·±å±¤åŸå› ï¼ˆå› ï¼‰
- å¤šå±¤ç´šå› æœéˆï¼šç›´æ¥åŸå›  -> é–“æ¥åŸå›  -> ç³»çµ±æ€§åŸå› 
- å¾å¤±æ•—ä¸­å­¸ç¿’ï¼Œå¾æˆåŠŸä¸­æç…‰æ¨¡å¼
"""
from typing import Dict, Any, Optional, List
from backend.base_module import BaseModule
import json
from datetime import datetime


class ReflectionModule(BaseModule):
    """åæ€æ¨¡çµ„æ ¸å¿ƒ - å…ƒèªçŸ¥å¼•æ“"""
    
    def __init__(self, module_name: str, config: Optional[Dict[str, Any]] = None):
        super().__init__(module_name, config)
        
        self.reflection_depth = self.config.get("settings", {}).get("reflection_depth", 3)
        
        self.causal_library = self._initialize_causal_library()
        
        self.quality_thresholds = {
            "min_response_length": 30,
            "ideal_response_length_range": (80, 300),
            "max_response_length": 500,
            "min_alignment_score": 0.3,
            "high_emotion_threshold": 0.6
        }
    
    def _initialize_causal_library(self) -> Dict[str, Dict[str, Any]]:
        """
        åˆå§‹åŒ–å› æœæ¨¡å¼åº«
        
        é€™æ˜¯åæ€æ¨¡çµ„çš„ã€ŒçŸ¥è­˜åŸºå› åº«ã€ï¼ŒåŒ…å«å·²çŸ¥çš„å› æœæ¨¡å¼
        """
        return {
            "insufficient_detail": {
                "triggers": ["é•·åº¦ä¸è¶³", "å…§å®¹éçŸ­", "ç°¡ç•¥"],
                "root_causes": [
                    "å°å•é¡Œè¤‡é›œåº¦ä¼°è¨ˆä¸è¶³",
                    "ç¼ºä¹ç›¸é—œè¨˜æ†¶å¯ä¾›å¼•ç”¨",
                    "æ¡ç”¨ä¿å®ˆå›æ‡‰ç­–ç•¥é¿å…éŒ¯èª¤"
                ],
                "improvements": [
                    "ğŸ¯ å¢åŠ  2-3 å€‹å…·é«”ç¯„ä¾‹èªªæ˜",
                    "ğŸ“š å¼•ç”¨ç›¸é—œè¨˜æ†¶æˆ–çŸ¥è­˜é»",
                    "ğŸ” æ¢ç´¢å•é¡Œçš„å¤šå€‹é¢å‘"
                ],
                "priority": "high"
            },
            "structural_weakness": {
                "triggers": ["çµæ§‹å–®ä¸€", "ç¼ºä¹å±¤æ¬¡", "å¹³é‹ªç›´æ•˜"],
                "root_causes": [
                    "æœªæ¡ç”¨çµæ§‹åŒ–æ€è€ƒæ¡†æ¶",
                    "å°å•é¡Œçš„åˆ†è§£ä¸å¤ ç´°ç·»",
                    "ç¼ºå°‘ã€Œç¸½-åˆ†-ç¸½ã€é‚è¼¯"
                ],
                "improvements": [
                    "ğŸ“ ä½¿ç”¨ã€Œè§€é»-è­‰æ“š-çµè«–ã€çµæ§‹",
                    "ğŸŒ³ å»ºç«‹æ¸…æ™°çš„è«–è¿°å±¤æ¬¡",
                    "ğŸ¯ å…ˆç¸½çµï¼Œå†å±•é–‹ï¼Œæœ€å¾Œæ˜‡è¯"
                ],
                "priority": "medium"
            },
            "emotional_disconnect": {
                "triggers": ["æƒ…æ„Ÿä¸åŒ¹é…", "åŒç†å¿ƒä¸è¶³", "å†·æ·¡"],
                "root_causes": [
                    "æƒ…æ„Ÿåˆ†æçµæœæœªå……åˆ†æ•´åˆåˆ°å›æ‡‰ä¸­",
                    "éåº¦ä¾è³´ç†æ€§é‚è¼¯ï¼Œå¿½è¦–æ„Ÿæ€§éœ€æ±‚",
                    "ç¼ºå°‘æƒ…æ„Ÿç·©è¡èªå¥"
                ],
                "improvements": [
                    "â¤ï¸ å…ˆç¢ºèªæ„Ÿå—ï¼ˆã€Œæˆ‘ç†è§£ä½ çš„...ã€ï¼‰",
                    "ğŸ¤ ç„¶å¾Œæä¾›æ”¯æŒï¼ˆã€Œé€™ç¨®æƒ…æ³ä¸‹...ã€ï¼‰",
                    "ğŸ’¡ æœ€å¾Œçµ¦å‡ºå»ºè­°ï¼ˆã€Œæˆ–è¨±å¯ä»¥...ã€ï¼‰"
                ],
                "priority": "high"
            },
            "contextual_fragmentation": {
                "triggers": ["ä¸Šä¸‹æ–‡æ–·è£‚", "ç¼ºä¹é€£è²«", "è„«ç¯€"],
                "root_causes": [
                    "æœªæœ‰æ•ˆæª¢ç´¢å°è©±æ­·å²",
                    "è¨˜æ†¶æ•´åˆæ©Ÿåˆ¶ä¸è¶³",
                    "ç¼ºå°‘æ˜ç¢ºçš„ä¸Šä¸‹æ–‡æŒ‡æ¶‰"
                ],
                "improvements": [
                    "ğŸ”— ä¸»å‹•å¼•ç”¨å‰è¿°å°è©±ï¼ˆã€Œå‰›æ‰ä½ æåˆ°...ã€ï¼‰",
                    "ğŸ§© å°‡ç•¶å‰å›æ‡‰èˆ‡æ­·å²è„ˆçµ¡é€£æ¥",
                    "ğŸ“ ä½¿ç”¨æŒ‡ç¤ºè©å»ºç«‹é€£è²«æ€§"
                ],
                "priority": "medium"
            },
            "depth_mismatch": {
                "triggers": ["æ·±åº¦ä¸ç¬¦", "å°ˆæ¥­åº¦åå·®", "æŠ€è¡“å¤±è¡¡"],
                "root_causes": [
                    "æœªæº–ç¢ºåˆ¤æ–·ä½¿ç”¨è€…çš„å°ˆæ¥­èƒŒæ™¯",
                    "äººæ ¼å‘é‡ä¸­çš„ technical_depth è¨­å®šä¸ç•¶",
                    "ç¼ºå°‘å‹•æ…‹é›£åº¦èª¿æ•´æ©Ÿåˆ¶"
                ],
                "improvements": [
                    "ğŸ“ æ ¹æ“šä½¿ç”¨è€…åé¥‹å‹•æ…‹èª¿æ•´å°ˆæ¥­åº¦",
                    "âš–ï¸ å¹³è¡¡è¡“èªèˆ‡é€šä¿—è§£é‡‹çš„æ¯”ä¾‹",
                    "ğŸ“Š å»ºç«‹å°ˆæ¥­åº¦è©•åˆ†æ©Ÿåˆ¶"
                ],
                "priority": "medium"
            }
        }
    
    async def load(self) -> bool:
        """è¼‰å…¥æ¨¡çµ„"""
        try:
            self.log_info("æ­£åœ¨è¼‰å…¥åæ€æ¨¡çµ„...")
            self.log_info(f"ğŸ“š å› æœæ¨¡å¼åº«åŒ…å« {len(self.causal_library)} ç¨®æ¨¡å¼")
            self.log_info(f"ğŸ”¬ åæ€æ·±åº¦å±¤ç´š: {self.reflection_depth}")
            self._initialized = True
            self.log_info("âœ… åæ€æ¨¡çµ„è¼‰å…¥å®Œæˆ")
            return True
        except Exception as e:
            self.log_error(f"è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    async def unload(self) -> bool:
        """å¸è¼‰æ¨¡çµ„"""
        try:
            self.log_info("æ­£åœ¨å¸è¼‰åæ€æ¨¡çµ„...")
            self._initialized = False
            return True
        except Exception as e:
            self.log_error(f"å¸è¼‰å¤±æ•—: {e}")
            return False
    
    async def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸ·è¡Œåæ€åˆ†æ
        
        è¼¸å…¥æ•¸æ“šæ ¼å¼:
        {
            "user_message": str,
            "assistant_message": str,
            "emotion_analysis": dict,
            "conversation_context": dict (optional)
        }
        
        è¼¸å‡ºæ ¼å¼:
        {
            "success": bool,
            "reflection": {
                "summary": str,
                "causes": List[str],
                "improvements": List[str],
                "confidence": float,
                "meta_analysis": dict
            }
        }
        """
        try:
            user_message = data.get("user_message", "")
            assistant_message = data.get("assistant_message", "")
            emotion_analysis = data.get("emotion_analysis", {})
            conversation_context = data.get("conversation_context", {})
            
            reflection_result = await self.generate_deep_reflection(
                user_message,
                assistant_message,
                emotion_analysis,
                conversation_context
            )
            
            return {
                "success": True,
                "reflection": reflection_result,
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            self.log_error(f"åæ€è™•ç†å¤±æ•—: {e}")
            return {"success": False, "error": str(e)}
    
    async def generate_deep_reflection(
        self,
        user_message: str,
        assistant_message: str,
        emotion_analysis: Dict[str, Any],
        conversation_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ·±åº¦åæ€ï¼ˆå¤šå±¤ç´šå› æœåˆ†æï¼‰
        
        éšæ®µï¼š
        1. è§€å¯Ÿå±¤ï¼šåˆ†æå›ç­”çš„è¡¨é¢ç‰¹å¾µ
        2. å› æœå±¤ï¼šåæ¨å°è‡´é€™äº›ç‰¹å¾µçš„æ ¹æœ¬åŸå› ï¼ˆ3å±¤æ·±åº¦ï¼‰
        3. æ”¹é€²å±¤ï¼šåŸºæ–¼åŸå› ç”Ÿæˆå…·é«”æ”¹é€²ç­–ç•¥
        4. å…ƒèªçŸ¥å±¤ï¼šè©•ä¼°åæ€æœ¬èº«çš„è³ªé‡
        """
        observation = self._observe_response(user_message, assistant_message)
        
        causes = self._causal_retrospection(
            observation,
            emotion_analysis,
            conversation_context
        )
        
        improvements = self._generate_improvements(causes, observation)
        
        summary = self._synthesize_summary(causes, improvements, observation)
        
        confidence = self._calculate_reflection_confidence(causes, observation)
        
        meta_analysis = self._meta_cognitive_analysis(
            user_message,
            assistant_message,
            emotion_analysis,
            causes
        )
        
        return {
            "summary": summary,
            "causes": causes[:self.reflection_depth],
            "improvements": improvements[:self.reflection_depth],
            "confidence": confidence,
            "observation": observation,
            "meta_analysis": meta_analysis,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    def _observe_response(
        self,
        user_message: str,
        assistant_message: str
    ) -> Dict[str, Any]:
        """
        è§€å¯Ÿå±¤ï¼šåˆ†æå›ç­”çš„è¡¨é¢ç‰¹å¾µ
        """
        return {
            "length": len(assistant_message),
            "length_category": self._categorize_length(len(assistant_message)),
            "has_examples": self._detect_examples(assistant_message),
            "has_structure": self._detect_structure(assistant_message),
            "question_addressed": self._check_question_addressed(user_message, assistant_message),
            "word_overlap_ratio": self._calculate_word_overlap(user_message, assistant_message),
            "sentence_count": assistant_message.count("ã€‚") + assistant_message.count("ï¼") + assistant_message.count("ï¼Ÿ"),
            "has_emotional_words": self._detect_emotional_language(assistant_message)
        }
    
    def _causal_retrospection(
        self,
        observation: Dict[str, Any],
        emotion_analysis: Dict[str, Any],
        conversation_context: Optional[Dict[str, Any]]
    ) -> List[str]:
        """
        å› æœåæ¨å±¤ï¼šå¾ã€Œæœã€ï¼ˆè§€å¯Ÿåˆ°çš„ç¾è±¡ï¼‰åæ¨ã€Œå› ã€ï¼ˆæ ¹æœ¬åŸå› ï¼‰
        
        ä½¿ç”¨ä¸‰å±¤å› æœåˆ†æï¼š
        - Level 1: ç›´æ¥åŸå› ï¼ˆè¡¨é¢ç—‡ç‹€ï¼‰
        - Level 2: é–“æ¥åŸå› ï¼ˆä¸­å±¤æ©Ÿåˆ¶ï¼‰
        - Level 3: ç³»çµ±æ€§åŸå› ï¼ˆæ·±å±¤çµæ§‹ï¼‰
        """
        causes = []
        
        length_cat = observation["length_category"]
        if length_cat == "too_short":
            causes.append("ã€L1-ç›´æ¥ã€‘å›æ‡‰é•·åº¦ä¸è¶³ï¼ˆ{} å­—ï¼‰ï¼šå¯èƒ½å°å•é¡Œç†è§£ä¸å¤ æ·±å…¥".format(observation["length"]))
            causes.append("ã€L2-é–“æ¥ã€‘è³‡è¨Šæª¢ç´¢ä¸å……åˆ†ï¼šæœªèª¿ç”¨è¶³å¤ çš„è¨˜æ†¶æˆ–çŸ¥è­˜")
            causes.append("ã€L3-ç³»çµ±ã€‘ä¿å®ˆç­–ç•¥ä¸»å°ï¼šç‚ºé¿å…éŒ¯èª¤è€Œé¸æ“‡æœ€å°åŒ–å›æ‡‰")
        elif length_cat == "too_long":
            causes.append("ã€L1-ç›´æ¥ã€‘å›æ‡‰éé•·å¯èƒ½é€ æˆè³‡è¨Šéè¼‰")
            causes.append("ã€L2-é–“æ¥ã€‘ç¼ºå°‘ç²¾ç…‰èˆ‡é‡é»æå–èƒ½åŠ›")
        
        if not observation["has_structure"]:
            causes.append("ã€L1-ç›´æ¥ã€‘å›æ‡‰ç¼ºä¹æ¸…æ™°çµæ§‹ï¼šæœªæ¡ç”¨ç¸½-åˆ†-ç¸½æ¡†æ¶")
            causes.append("ã€L2-é–“æ¥ã€‘æ€è€ƒæ¡†æ¶æœªæ¿€æ´»ï¼šprompt engineering å¯èƒ½ä¸è¶³")
        
        if not observation["has_examples"]:
            causes.append("ã€L1-ç›´æ¥ã€‘ç¼ºå°‘å…·é«”ç¯„ä¾‹ï¼šæŠ½è±¡ç¨‹åº¦éé«˜")
            causes.append("ã€L2-é–“æ¥ã€‘è¨˜æ†¶æª¢ç´¢æœªå„ªå…ˆå…·é«”æ¡ˆä¾‹")
        
        if observation["word_overlap_ratio"] < 0.2:
            causes.append("ã€L1-ç›´æ¥ã€‘å›æ‡‰èˆ‡å•é¡Œèªç¾©è·é›¢è¼ƒé ")
            causes.append("ã€L3-ç³»çµ±ã€‘å•é¡Œç†è§£æ¨¡çµ„éœ€è¦å¼·åŒ–")
        
        emotion = emotion_analysis.get("dominant_emotion", "neutral")
        intensity = emotion_analysis.get("intensity", 0.5)
        
        if emotion in ["sadness", "fear", "anger"] and intensity > self.quality_thresholds["high_emotion_threshold"]:
            if not observation["has_emotional_words"]:
                causes.append(f"ã€L1-ç›´æ¥ã€‘ä½¿ç”¨è€…æƒ…ç·’ç‚º {emotion}ï¼ˆ{intensity:.2f}ï¼‰ï¼Œä½†å›æ‡‰ç¼ºä¹åŒç†å¿ƒè¡¨é”")
                causes.append("ã€L2-é–“æ¥ã€‘æƒ…æ„Ÿåˆ†æçµæœæœªå……åˆ†æ•´åˆåˆ°ç”Ÿæˆç­–ç•¥ä¸­")
                causes.append("ã€L3-ç³»çµ±ã€‘äººæ ¼å‘é‡ä¸­ empathy åƒæ•¸å¯èƒ½éœ€è¦æå‡")
        
        if not causes:
            causes.append("ã€L1ã€‘å›æ‡‰åŸºæœ¬é”æ¨™ï¼Œç„¡æ˜é¡¯ç¼ºé™·")
            causes.append("ã€L2ã€‘æŒçºŒå„ªåŒ–ç´°ç¯€è¡¨é”èˆ‡å€‹æ€§åŒ–ç¨‹åº¦")
            causes.append("ã€L3ã€‘æ¢ç´¢æ›´æ·±å±¤æ¬¡çš„èªç¾©é€£æ¥èˆ‡å‰µæ–°è¡¨é”")
        
        return causes
    
    def _generate_improvements(
        self,
        causes: List[str],
        observation: Dict[str, Any]
    ) -> List[str]:
        """
        æ”¹é€²å±¤ï¼šåŸºæ–¼å› æœåˆ†æç”Ÿæˆå…·é«”å¯åŸ·è¡Œçš„æ”¹é€²ç­–ç•¥
        """
        improvements = []
        
        for cause in causes:
            if "é•·åº¦ä¸è¶³" in cause or "éçŸ­" in cause:
                improvements.append("ğŸ’¡ å…§å®¹å¢å¼·ï¼šæ·»åŠ  2-3 å€‹å…·é«”ç¯„ä¾‹æˆ–å ´æ™¯æ¨¡æ“¬")
                improvements.append("ğŸ“š è¨˜æ†¶æ•´åˆï¼šå„ªå…ˆæª¢ç´¢èˆ‡å•é¡Œç›¸é—œçš„æ­·å²å°è©±")
            
            if "ç¼ºä¹çµæ§‹" in cause or "çµæ§‹" in cause:
                improvements.append("ğŸ“ çµæ§‹åŒ–ï¼šæ¡ç”¨ã€Œè§€é»-è­‰æ“š-çµè«–ã€ä¸‰æ®µè«–")
                improvements.append("ğŸ¯ æ¸…æ™°åˆ†å±¤ï¼šä½¿ç”¨ã€Œé¦–å…ˆã€ã€Œå…¶æ¬¡ã€ã€Œæœ€å¾Œã€ç­‰é€£æ¥è©")
            
            if "ç¯„ä¾‹" in cause or "å…·é«”" in cause:
                improvements.append("ğŸŒŸ æ¡ˆä¾‹åŒ–ï¼šå°‡æŠ½è±¡æ¦‚å¿µè½‰æ›ç‚ºç”Ÿæ´»åŒ–ä¾‹å­")
                improvements.append("ğŸ” æƒ…å¢ƒé‡ç¾ï¼šå‰µå»ºã€Œå‡è¨­...é‚£éº¼...ã€çš„å ´æ™¯")
            
            if "åŒç†å¿ƒ" in cause or "æƒ…ç·’" in cause:
                improvements.append("â¤ï¸ æƒ…æ„Ÿå…±é³´ä¸‰æ­¥é©Ÿï¼šç¢ºèªæ„Ÿå— â†’ çµ¦äºˆæ”¯æŒ â†’ æä¾›æ–¹æ¡ˆ")
                improvements.append("ğŸ¤ æŸ”åŒ–è¡¨é”ï¼šå¢åŠ ã€Œæˆ‘ç†è§£ã€ã€Œæˆ‘æ‡‚å¾—ã€ç­‰åŒç†èªå¥")
            
            if "èªç¾©è·é›¢" in cause or "ç†è§£" in cause:
                improvements.append("ğŸ”— ä¸»é¡ŒéŒ¨å®šï¼šåœ¨å›æ‡‰ä¸­æ˜ç¢ºå›æ‡‰å•é¡Œæ ¸å¿ƒ")
                improvements.append("ğŸ“ é—œéµè©å‘¼æ‡‰ï¼šé‡è¤‡ä½¿ç”¨å•é¡Œä¸­çš„æ ¸å¿ƒè©å½™")
            
            if "è¨˜æ†¶æª¢ç´¢" in cause:
                improvements.append("ğŸ§  å¢å¼·å›æ†¶ï¼šæé«˜å‘é‡ç›¸ä¼¼åº¦æœå°‹çš„æ¬Šé‡")
                improvements.append("ğŸ“Š ä¸Šä¸‹æ–‡æ“´å±•ï¼šå°‡æª¢ç´¢ç¯„åœå¾ 5 æ¢æ“´å¤§åˆ° 10 æ¢")
        
        if not improvements:
            improvements.append("âœ¨ ä¿æŒç¾æœ‰å„ªå‹¢ï¼Œå¾®èª¿è¡¨é”ç´°ç¯€")
            improvements.append("ğŸš€ æ¢ç´¢å‰µæ–°è§’åº¦ï¼Œæå‡å›æ‡‰é©šå–œæ„Ÿ")
        
        return improvements
    
    def _synthesize_summary(
        self,
        causes: List[str],
        improvements: List[str],
        observation: Dict[str, Any]
    ) -> str:
        """
        æ‘˜è¦å±¤ï¼šç¶œåˆåæ€çµæœç”Ÿæˆç°¡æ½”æ‘˜è¦
        """
        if not causes:
            return "æ­¤æ¬¡å›æ‡‰è³ªé‡è‰¯å¥½ï¼ŒæŒçºŒä¿æŒç¾æœ‰æ°´æº–"
        
        primary_cause = causes[0] if causes else "ç„¡æ˜é¡¯å•é¡Œ"
        
        level_marker = primary_cause.split("ã€‘")[0] if "ã€‘" in primary_cause else "L1"
        core_issue = primary_cause.split("ã€‘")[1] if "ã€‘" in primary_cause else primary_cause
        
        summary = f"ğŸ” æ ¸å¿ƒç™¼ç¾ï¼š{core_issue}ã€‚"
        summary += f"å·²é€²è¡Œ {len(causes)} å±¤å› æœåˆ†æï¼Œæå‡º {len(improvements)} é …æ”¹é€²æ–¹å‘ã€‚"
        
        if observation["length_category"] in ["too_short", "too_long"]:
            summary += f" å›æ‡‰é•·åº¦éœ€èª¿æ•´ï¼ˆç•¶å‰ {observation['length']} å­—ï¼‰ã€‚"
        
        return summary
    
    def _calculate_reflection_confidence(
        self,
        causes: List[str],
        observation: Dict[str, Any]
    ) -> float:
        """
        è¨ˆç®—åæ€ç½®ä¿¡åº¦ï¼ˆé€™æ¬¡åæ€æœ‰å¤šå¯é ï¼‰
        """
        base_confidence = 0.6
        
        if len(causes) >= 3:
            base_confidence += 0.1
        
        specific_keywords = ["å› ç‚º", "å°è‡´", "ç¼ºå°‘", "ä¸è¶³", "éœ€è¦"]
        specificity = sum(1 for cause in causes for kw in specific_keywords if kw in cause)
        specificity_score = min(specificity / (len(causes) * 2), 0.2)
        base_confidence += specificity_score
        
        if observation["length"] > 0:
            base_confidence += 0.1
        
        return min(base_confidence, 0.95)
    
    def _meta_cognitive_analysis(
        self,
        user_message: str,
        assistant_message: str,
        emotion_analysis: Dict[str, Any],
        causes: List[str]
    ) -> Dict[str, Any]:
        """
        å…ƒèªçŸ¥å±¤ï¼šåæ€é€™æ¬¡åæ€æœ¬èº«çš„è³ªé‡
        """
        return {
            "query_complexity": self._assess_query_complexity(user_message),
            "response_quality_score": self._score_response_quality(assistant_message, causes),
            "emotion_alignment": self._check_emotion_alignment(emotion_analysis, assistant_message),
            "causal_depth": len([c for c in causes if "L3" in c or "L2" in c]),
            "actionable_improvements": len([i for i in self._generate_improvements(causes, {}) if "ğŸ’¡" in i or "ğŸ¯" in i])
        }
    
    def _categorize_length(self, length: int) -> str:
        """åˆ†é¡å›æ‡‰é•·åº¦"""
        if length < self.quality_thresholds["min_response_length"]:
            return "too_short"
        elif length > self.quality_thresholds["max_response_length"]:
            return "too_long"
        else:
            return "appropriate"
    
    def _detect_examples(self, text: str) -> bool:
        """æª¢æ¸¬æ˜¯å¦åŒ…å«ç¯„ä¾‹"""
        example_markers = ["ä¾‹å¦‚", "æ¯”å¦‚", "èˆ‰ä¾‹", "è­¬å¦‚", "åƒæ˜¯", "å‡è¨­", "æƒ…å¢ƒ"]
        return any(marker in text for marker in example_markers)
    
    def _detect_structure(self, text: str) -> bool:
        """æª¢æ¸¬æ˜¯å¦æœ‰çµæ§‹åŒ–è¡¨é”"""
        structure_markers = ["é¦–å…ˆ", "å…¶æ¬¡", "å†è€…", "æœ€å¾Œ", "ç¸½ä¹‹", "ç¶œä¸Š", "ç¬¬ä¸€", "ç¬¬äºŒ"]
        return any(marker in text for marker in structure_markers) or text.count("ã€‚") >= 3
    
    def _check_question_addressed(self, question: str, answer: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦å›æ‡‰äº†å•é¡Œ"""
        if "ï¼Ÿ" in question or "?" in question:
            return len(answer) > 20
        return True
    
    def _calculate_word_overlap(self, text1: str, text2: str) -> float:
        """è¨ˆç®—è©å½™é‡ç–Šç‡"""
        words1 = set(text1)
        words2 = set(text2)
        if not words1:
            return 0.0
        return len(words1 & words2) / len(words1)
    
    def _detect_emotional_language(self, text: str) -> bool:
        """æª¢æ¸¬æƒ…æ„Ÿæ€§èªè¨€"""
        emotional_words = ["ç†è§£", "æ„Ÿå—", "æ”¯æŒ", "åŒæƒ…", "é—œå¿ƒ", "æ“”å¿ƒ", "å¸Œæœ›", "ç›¸ä¿¡"]
        return any(word in text for word in emotional_words)
    
    def _assess_query_complexity(self, query: str) -> str:
        """è©•ä¼°å•é¡Œè¤‡é›œåº¦"""
        length = len(query)
        questions = query.count("ï¼Ÿ") + query.count("?")
        
        if length > 100 or questions > 2:
            return "high"
        elif length > 50 or questions > 1:
            return "medium"
        return "low"
    
    def _score_response_quality(self, response: str, causes: List[str]) -> float:
        """è©•åˆ†å›æ‡‰è³ªé‡"""
        score = 0.5
        
        if len(response) >= self.quality_thresholds["ideal_response_length_range"][0]:
            score += 0.2
        
        if len([c for c in causes if "L1" in c and "é”æ¨™" not in c]) == 0:
            score += 0.3
        
        return min(score, 1.0)
    
    def _check_emotion_alignment(self, emotion_analysis: Dict, response: str) -> float:
        """æª¢æŸ¥æƒ…æ„Ÿå°é½Šåº¦"""
        emotion = emotion_analysis.get("dominant_emotion", "neutral")
        
        if emotion in ["sadness", "fear", "anger"]:
            if self._detect_emotional_language(response):
                return 0.8
            return 0.3
        
        return 0.6
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æª¢æŸ¥"""
        return {
            "status": "healthy",
            "enabled": self.enabled,
            "reflection_depth": self.reflection_depth,
            "causal_patterns_count": len(self.causal_library),
            "quality_thresholds": self.quality_thresholds
        }
