from fastapi import APIRouter, HTTPException, BackgroundTasks # âœ… åŒ¯å…¥ BackgroundTasks
from pydantic import BaseModel
from typing import Optional
import os
import logging
import json
import asyncio # âœ… æ–°å¢åŒ¯å…¥ï¼Œç”¨æ–¼å¾Œå°ä»»å‹™

# *** è«‹ç¢ºä¿é€™äº›æ¨¡çµ„åœ¨ä½ çš„ backend/ ç›®éŒ„ä¸­å¯è¢«æ­£ç¢ºåŒ¯å…¥ ***
from backend.supabase_handler import get_supabase
supabase = get_supabase()
from backend.openai_handler import get_openai_client, generate_response
from backend.prompt_engine import PromptEngine
from modules.memory_system import MemorySystem
from backend.modules.memory.redis_interface import RedisInterface
from backend.core_controller import get_core_controller # ç¢ºä¿ core_controller æ”¾åœ¨é ‚å±¤

router = APIRouter()
logger = logging.getLogger("chat_router")
redis_interface = RedisInterface()

# === å»¶é²åˆå§‹åŒ–å‡½æ•¸ç¶­æŒä¸è®Š ===
# ï¼ˆæ­¤è™•çœç•¥ get_new_memory_core, get_reflection_storage çš„ç¨‹å¼ç¢¼ï¼Œè«‹ä¿æŒå…¶åœ¨ä½ çš„æ–‡ä»¶ä¸­ï¼‰

# chat_router.py (ChatRequest æ¨¡çµ„è¨­å®š)
class ChatRequest(BaseModel):
    user_message: str
    conversation_id: str
    user_id: str = "default_user"
    # âœ… æ–°å¢ AI å¯¶è²åˆ‡æ›é–‹é—œ (é è¨­ç‚º xiaochenguang_v1)
    ai_id: str = os.getenv("AI_ID", "xiaochenguang_v1") 
    
    # é€™è£¡å¯ä»¥åŠ å…¥æ›´å¤šä½ æƒ³è§€å¯Ÿçš„åƒæ•¸
    # temperature: float = 0.8
    # top_p: float = 1.0
class ChatResponse(BaseModel):
    assistant_message: str
    emotion_analysis: dict
    conversation_id: str
    # å°‡ reflection è¨­ç‚º Noneï¼Œå› ç‚ºå®ƒå°‡åœ¨èƒŒæ™¯è™•ç†ï¼Œä¸æœƒç«‹å³è¿”å›
    reflection: Optional[dict] = None 

# =========================================================
# âœ… æ ¸å¿ƒï¼šã€éš±å½¢å¾Œé–€é€šé“ã€‘çš„è™•ç†å‡½æ•¸ (Background Task Function)
# =========================================================
async def run_post_chat_tasks(
    request: ChatRequest, assistant_message: str, emotion_analysis: dict
):
    """
    æ­¤å‡½æ•¸è² è²¬æ‰€æœ‰è€—æ™‚çš„ã€ä¸å½±éŸ¿å³æ™‚å›è¦†çš„å¾ŒçºŒè™•ç†å·¥ä½œï¼š
    åæ€ã€è¡Œç‚ºèª¿ç¯€ã€ä¸‰å±¤è¨˜æ†¶å„²å­˜ç­‰ã€‚
    """
    logger.info(f"ğŸŸ¢ å•Ÿå‹•èƒŒæ™¯è™•ç†ä»»å‹™ï¼Œè™•ç† conversation_id: {request.conversation_id}")
    
    # å†æ¬¡å¯¦ä¾‹åŒ–æˆ–ç²å–å¿…è¦çš„æœå‹™ï¼Œç¢ºä¿å®ƒå€‘åœ¨èƒŒæ™¯ä»»å‹™ä¸­å¯ç”¨
    openai_client = get_openai_client()
    memories_table = os.getenv("SUPABASE_MEMORIES_TABLE", "xiaochenguang_memories")
    memory_system = MemorySystem(supabase, openai_client, memories_table)
    prompt_engine = PromptEngine(request.conversation_id, memories_table)
    
    reflection_result = None
    
    try:
        controller = await get_core_controller()
        
        # *** ä»¥ä¸‹æ˜¯ä½ çš„åŸä»£ç¢¼ä¸­ï¼Œå¾ã€Œåæ€åˆ†æã€é–‹å§‹çš„æ‰€æœ‰é‚è¼¯ ***
        
        # === éšæ®µ1ï¼šåæ€åˆ†æ ===
        reflection_module = await controller.get_module("reflection")
        if reflection_module:
            reflection_response = await reflection_module.process({
                "user_message": request.user_message,
                "assistant_message": assistant_message,
                "emotion_analysis": emotion_analysis
            })
            
            if reflection_response.get("success"):
                reflection_result = reflection_response.get("reflection")
                logger.info(f"ğŸ§  èƒŒæ™¯ï¼šåæ€å®Œæˆï¼ˆç½®ä¿¡åº¦: {reflection_result.get('confidence', 0):.2f}ï¼‰")
                
                # === éšæ®µ1.5ï¼šåæ€å„²å­˜ï¼ˆä¸‰å±¤æ¶æ§‹ï¼‰===
                reflection_storage = get_reflection_storage()
                if reflection_storage and reflection_result:
                    # è¨»ï¼šé€™è£¡å¯ä»¥è€ƒæ…®ä½¿ç”¨ asyncio.gather ä¾†ä¸¦è¡Œå„²å­˜ï¼Œé€²ä¸€æ­¥å„ªåŒ–èƒŒæ™¯é€Ÿåº¦
                    storage_result = await reflection_storage.store_reflection(
                        reflection_data=reflection_result,
                        conversation_id=request.conversation_id,
                        user_id=request.user_id,
                        related_message_id=None
                    )
                    if storage_result.get("overall_success"):
                        logger.info(f"ğŸ’¾ èƒŒæ™¯ï¼šåæ€å·²å„²å­˜åˆ°ä¸‰å±¤æ¶æ§‹")
                    else:
                        logger.warning(f"âš ï¸ èƒŒæ™¯ï¼šåæ€å„²å­˜éƒ¨åˆ†å¤±æ•—")
                
                # === éšæ®µ2ï¼šè¡Œç‚ºèª¿ç¯€ï¼ˆåŸºæ–¼åæ€çµæœï¼‰===
                behavior_module = await controller.get_module("behavior")
                if behavior_module and reflection_result:
                    behavior_response = await behavior_module.process({
                        "reflection": reflection_result,
                        # ... å…¶ä»–ä¸Šä¸‹æ–‡ ...
                    })
                    if behavior_response.get("success"):
                        logger.info(f"ğŸ¯ èƒŒæ™¯ï¼šäººæ ¼èª¿æ•´å·²å®Œæˆ")
        
        # === é¡å¤–ï¼šå°‡å³æ™‚å„²å­˜ä¹Ÿæ”¾å…¥èƒŒæ™¯ï¼Œåªåœ¨å›è¦†å¾ŒåŸ·è¡Œ ===
        await memory_system.save_emotional_state(
            request.user_id,
            emotion_analysis,
            context=request.user_message
        )
        prompt_engine.personality_engine.learn_from_interaction(
            request.user_message,
            assistant_message,
            emotion_analysis
        )
        await asyncio.to_thread(prompt_engine.personality_engine.save_personality) # ç¢ºä¿åŒæ­¥å¯«å…¥è¢«å®‰å…¨è™•ç†
        
        # === éšæ®µ3ï¼šè¨˜æ†¶å„²å­˜ï¼ˆå«åæ€èˆ‡è¡Œç‚ºèª¿æ•´ï¼‰===
        new_memory = get_new_memory_core()
        if new_memory:
            result = new_memory.store_conversation(
                # ... å„²å­˜åƒæ•¸ ...
                reflection=reflection_result
            )
            if result.get("success"):
                logger.info(f"ğŸ’¾ èƒŒæ™¯ï¼šæ–°è¨˜æ†¶æ¨¡çµ„å·²å„²å­˜")
                
    except Exception as e:
        logger.warning(f"âš ï¸ èƒŒæ™¯ä»»å‹™è™•ç†å¤±æ•—: {e}", exc_info=True)


# =========================================================
# âœ… ä¸»æµç¨‹ï¼š/chat è·¯ç”±ï¼ˆåªè² è²¬å›è¦†ï¼‰
# =========================================================
@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest, background_tasks: BackgroundTasks): # âœ… æ³¨å…¥ BackgroundTasks
    try:
        logger.info(f"ğŸŸ¢ æ¥æ”¶åˆ°èŠå¤©è«‹æ±‚ï¼Œconversation_id: {request.conversation_id}")
        openai_client = get_openai_client()
        memories_table = os.getenv("SUPABASE_MEMORIES_TABLE", "xiaochenguang_memories")

        memory_system = MemorySystem(supabase, openai_client, memories_table)
        prompt_engine = PromptEngine(request.conversation_id, memories_table)

        # 1. åŸ·è¡Œæ‰€æœ‰ã€Œè®€å–ã€ä»»å‹™ï¼ˆé€™å¿…é ˆæ˜¯åŒæ­¥çš„ï¼‰
        recalled_memories = await memory_system.recall_memories(...)
        conversation_history = memory_system.get_conversation_history(...)
        file_content = "" # å¾ Redis æª¢ç´¢æª”æ¡ˆå…§å®¹çš„é‚è¼¯ä¹Ÿä¿ç•™

        messages, emotion_analysis = await prompt_engine.build_prompt(
            request.user_message, recalled_memories, conversation_history, file_content
        )

        # 2. å‘¼å« OpenAI ç²å¾—å›è¦†ï¼ˆä¸»æµç¨‹çš„ç­‰å¾…é»ï¼‰
        assistant_message = await generate_response(
            openai_client, messages, model="gpt-4o-mini", max_tokens=1000, temperature=0.8
        )
        
        # 3. [é‡è¦] ä¿æŒæ ¸å¿ƒè¨˜æ†¶ç«‹å³å„²å­˜ (ç¢ºä¿ä¸»è¨Šæ¯ä¸æœƒä¸Ÿå¤±)
        await memory_system.save_memory(
            request.conversation_id, request.user_message, assistant_message,
            emotion_analysis, ai_id=os.getenv("AI_ID", "xiaochenguang_v1")
        )

        # âœ… ã€æ ¸å¿ƒå‹•ä½œã€‘å°‡æ‰€æœ‰è€—æ™‚çš„ã€Œæ¬å®¶éšŠä¼ã€æ¨å…¥å¾Œé–€é€šé“ï¼
        background_tasks.add_task(
            run_post_chat_tasks,
            request, 
            assistant_message, 
            emotion_analysis
        )

        # 4. ç«‹å³è¿”å›çµ¦ç”¨æˆ¶ï¼Œä¸å†ç­‰å¾…èƒŒæ™¯ä»»å‹™
        return ChatResponse(
            assistant_message=assistant_message,
            emotion_analysis=emotion_analysis,
            conversation_id=request.conversation_id,
            reflection=None # ä¸å†ç­‰å¾… reflection çµæœ
        )

    except Exception as e:
        # ä¿æŒä½ çš„éŒ¯èª¤è™•ç†é‚è¼¯
        import traceback
        traceback_str = traceback.format_exc()
        logger.error(f"ğŸ”¥ Chat Endpoint ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="è¼‰é«”å…§éƒ¨å…‰æµç•°å¸¸ï¼Œè«‹æª¢æŸ¥æ—¥èªŒã€‚")
